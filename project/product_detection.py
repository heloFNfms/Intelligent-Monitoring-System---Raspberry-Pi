"""
äº§å“æ£€æµ‹ç³»ç»Ÿ - æ£€æµ‹ä¼ é€å¸¦ä¸Šç‰©å“çš„é¢œè‰²å’Œå½¢çŠ¶
åŠŸèƒ½ï¼š
1. æ‰“å¼€æ‘„åƒå¤´è¯†åˆ«ç‰©å“
2. æ ¹æ®é¢œè‰²åˆ¤æ–­äº§å“ç±»å‹ï¼ˆè“è‰²=äº§å“Aï¼Œé’è‰²=äº§å“Bï¼‰
3. æ ¹æ®å½¢çŠ¶åˆ¤æ–­äº§å“ç±»å‹ï¼ˆæ–¹å½¢=äº§å“Aï¼Œåœ†å½¢=äº§å“Bï¼‰
4. ä¸ŠæŠ¥æ£€æµ‹ç»“æœåˆ°åç«¯

é€‚ç”¨äºï¼šæ ‘è“æ´¾æ‘„åƒå¤´ / ç¬”è®°æœ¬æ‘„åƒå¤´
"""

import cv2
import numpy as np
from datetime import datetime
from typing import Tuple, Optional, Dict, List
import time
import threading
import platform
import base64
import requests

# æ£€æµ‹æ“ä½œç³»ç»Ÿ
IS_WINDOWS = platform.system() == "Windows"
IS_LINUX = platform.system() == "Linux"

# ==================== æœåŠ¡å™¨é…ç½® ====================
SERVER_URL = "http://localhost:8000"
DEVICE_ID = "device_001"
ENABLE_SERVER_REPORT = True
ENABLE_VIDEO_STREAM = True
VIDEO_STREAM_FPS = 10
VIDEO_QUALITY = 60


class ProductDetector:
    """
    äº§å“æ£€æµ‹å™¨ - åŸºäºé¢œè‰²å’Œå½¢çŠ¶è¯†åˆ«äº§å“ç±»å‹
    
    äº§å“A: è“è‰² + æ–¹å½¢
    äº§å“B: é’è‰² + åœ†å½¢
    """
    
    # é¢œè‰²èŒƒå›´å®šä¹‰ (HSV)
    COLOR_RANGES = {
        "product_a": {  # è“è‰²
            "lower": np.array([100, 100, 100]),
            "upper": np.array([130, 255, 255]),
            "name": "è“è‰²",
            "display_color": (255, 150, 50)  # BGR
        },
        "product_b": {  # é’è‰²
            "lower": np.array([75, 100, 100]),
            "upper": np.array([95, 255, 255]),
            "name": "é’è‰²",
            "display_color": (200, 200, 50)  # BGR
        },
        "red": {  # çº¢è‰²ï¼ˆå¯ç”¨äºä¸åˆæ ¼å“ï¼‰
            "lower": np.array([0, 100, 100]),
            "upper": np.array([10, 255, 255]),
            "name": "çº¢è‰²",
            "display_color": (50, 50, 255)
        }
    }
    
    # å½¢çŠ¶åˆ¤æ–­å‚æ•°
    SHAPE_CIRCULARITY_THRESHOLD = 0.7  # åœ†å½¢åº¦é˜ˆå€¼
    MIN_CONTOUR_AREA = 1000  # æœ€å°è½®å»“é¢ç§¯
    MAX_CONTOUR_AREA = 100000  # æœ€å¤§è½®å»“é¢ç§¯
    
    def __init__(self):
        self.detection_count = {
            "product_a": 0,
            "product_b": 0,
            "unknown": 0
        }
        self.last_detection_time = 0
        self.detection_cooldown = 1.0  # æ£€æµ‹å†·å´æ—¶é—´ï¼ˆç§’ï¼‰
        self.last_stream_time = 0
        self.stream_interval = 1.0 / VIDEO_STREAM_FPS
        
        print("âœ“ äº§å“æ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"  äº§å“A: è“è‰²æ–¹å½¢")
        print(f"  äº§å“B: é’è‰²åœ†å½¢")
    
    def detect_color(self, frame: np.ndarray, roi: Tuple[int, int, int, int] = None) -> Tuple[str, np.ndarray]:
        """
        æ£€æµ‹å›¾åƒä¸­çš„ä¸»è¦é¢œè‰²
        
        Args:
            frame: BGRå›¾åƒ
            roi: æ„Ÿå…´è¶£åŒºåŸŸ (x, y, w, h)ï¼ŒNoneè¡¨ç¤ºå…¨å›¾
        
        Returns:
            (äº§å“ç±»å‹, æ©ç å›¾åƒ)
        """
        if roi:
            x, y, w, h = roi
            region = frame[y:y+h, x:x+w]
        else:
            region = frame
        
        # è½¬æ¢åˆ°HSVè‰²å½©ç©ºé—´
        hsv = cv2.cvtColor(region, cv2.COLOR_BGR2HSV)
        
        best_match = "unknown"
        best_area = 0
        best_mask = None
        
        for product_type, color_range in self.COLOR_RANGES.items():
            if product_type not in ["product_a", "product_b"]:
                continue
                
            # åˆ›å»ºé¢œè‰²æ©ç 
            mask = cv2.inRange(hsv, color_range["lower"], color_range["upper"])
            
            # å½¢æ€å­¦æ“ä½œå»å™ª
            kernel = np.ones((5, 5), np.uint8)
            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
            
            # è®¡ç®—é¢œè‰²åŒºåŸŸé¢ç§¯
            area = cv2.countNonZero(mask)
            
            if area > best_area and area > self.MIN_CONTOUR_AREA:
                best_area = area
                best_match = product_type
                best_mask = mask
        
        return best_match, best_mask if best_mask is not None else np.zeros_like(frame[:,:,0])
    
    def detect_shape(self, mask: np.ndarray) -> Tuple[str, List[np.ndarray]]:
        """
        æ£€æµ‹æ©ç ä¸­çš„å½¢çŠ¶
        
        Args:
            mask: äºŒå€¼æ©ç å›¾åƒ
        
        Returns:
            (å½¢çŠ¶ç±»å‹, è½®å»“åˆ—è¡¨)
        """
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if not contours:
            return "unknown", []
        
        # æ‰¾æœ€å¤§è½®å»“
        valid_contours = [c for c in contours 
                         if self.MIN_CONTOUR_AREA < cv2.contourArea(c) < self.MAX_CONTOUR_AREA]
        
        if not valid_contours:
            return "unknown", []
        
        largest_contour = max(valid_contours, key=cv2.contourArea)
        
        # è®¡ç®—åœ†å½¢åº¦
        area = cv2.contourArea(largest_contour)
        perimeter = cv2.arcLength(largest_contour, True)
        
        if perimeter == 0:
            return "unknown", valid_contours
        
        circularity = 4 * np.pi * area / (perimeter * perimeter)
        
        # åˆ¤æ–­å½¢çŠ¶
        if circularity > self.SHAPE_CIRCULARITY_THRESHOLD:
            return "circle", valid_contours  # åœ†å½¢ -> äº§å“B
        else:
            return "rectangle", valid_contours  # æ–¹å½¢ -> äº§å“A
    
    def detect_product(self, frame: np.ndarray) -> Dict:
        """
        ç»¼åˆæ£€æµ‹äº§å“ç±»å‹
        
        Args:
            frame: BGRå›¾åƒ
        
        Returns:
            æ£€æµ‹ç»“æœå­—å…¸
        """
        result = {
            "detected": False,
            "product_type": "unknown",
            "color": "unknown",
            "shape": "unknown",
            "confidence": 0.0,
            "contours": [],
            "bbox": None
        }
        
        # 1. é¢œè‰²æ£€æµ‹
        color_type, mask = self.detect_color(frame)
        
        if color_type == "unknown":
            return result
        
        # 2. å½¢çŠ¶æ£€æµ‹
        shape_type, contours = self.detect_shape(mask)
        
        if shape_type == "unknown":
            return result
        
        # 3. ç»¼åˆåˆ¤æ–­
        # äº§å“A: è“è‰² + æ–¹å½¢
        # äº§å“B: é’è‰² + åœ†å½¢
        if color_type == "product_a" and shape_type == "rectangle":
            product_type = "product_a"
            confidence = 0.9
        elif color_type == "product_b" and shape_type == "circle":
            product_type = "product_b"
            confidence = 0.9
        elif color_type == "product_a":
            product_type = "product_a"
            confidence = 0.7
        elif color_type == "product_b":
            product_type = "product_b"
            confidence = 0.7
        else:
            product_type = "unknown"
            confidence = 0.3
        
        # è®¡ç®—è¾¹ç•Œæ¡†
        if contours:
            largest = max(contours, key=cv2.contourArea)
            x, y, w, h = cv2.boundingRect(largest)
            result["bbox"] = (x, y, w, h)
        
        result.update({
            "detected": True,
            "product_type": product_type,
            "color": self.COLOR_RANGES.get(color_type, {}).get("name", "æœªçŸ¥"),
            "shape": "åœ†å½¢" if shape_type == "circle" else "æ–¹å½¢",
            "confidence": confidence,
            "contours": contours
        })
        
        return result
    
    def draw_detection(self, frame: np.ndarray, result: Dict) -> np.ndarray:
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ
        """
        output = frame.copy()
        h, w = output.shape[:2]
        
        # ç»˜åˆ¶æ£€æµ‹åŒºåŸŸæ¡†
        cv2.rectangle(output, (50, 50), (w-50, h-50), (100, 100, 100), 2)
        cv2.putText(output, "Detection Area", (55, 45), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (100, 100, 100), 1)
        
        if result["detected"]:
            # ç»˜åˆ¶è½®å»“
            for contour in result["contours"]:
                if result["product_type"] == "product_a":
                    color = self.COLOR_RANGES["product_a"]["display_color"]
                elif result["product_type"] == "product_b":
                    color = self.COLOR_RANGES["product_b"]["display_color"]
                else:
                    color = (128, 128, 128)
                
                cv2.drawContours(output, [contour], -1, color, 3)
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†å’Œæ ‡ç­¾
            if result["bbox"]:
                x, y, bw, bh = result["bbox"]
                cv2.rectangle(output, (x, y), (x+bw, y+bh), color, 2)
                
                # äº§å“ç±»å‹æ ‡ç­¾
                label = f"{result['product_type'].upper()}"
                if result["product_type"] == "product_a":
                    label = "Product A (Blue/Square)"
                elif result["product_type"] == "product_b":
                    label = "Product B (Cyan/Circle)"
                
                cv2.putText(output, label, (x, y-10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
                
                # ç½®ä¿¡åº¦
                conf_text = f"Conf: {result['confidence']:.0%}"
                cv2.putText(output, conf_text, (x, y+bh+20),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
        
        # ç»˜åˆ¶ç»Ÿè®¡ä¿¡æ¯
        stats_y = 30
        cv2.putText(output, f"Product A: {self.detection_count['product_a']}", 
                   (10, stats_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, 
                   self.COLOR_RANGES["product_a"]["display_color"], 2)
        cv2.putText(output, f"Product B: {self.detection_count['product_b']}", 
                   (10, stats_y + 25), cv2.FONT_HERSHEY_SIMPLEX, 0.6,
                   self.COLOR_RANGES["product_b"]["display_color"], 2)
        
        # æ“ä½œæç¤º
        cv2.putText(output, "Press 'c' to capture | 'r' to reset | 'q' to quit",
                   (10, h - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
        
        return output
    
    def capture_and_detect(self, frame: np.ndarray) -> Dict:
        """
        æ•è·å¹¶æ£€æµ‹äº§å“ï¼ˆå¸¦å†·å´æ—¶é—´ï¼‰
        """
        current_time = time.time()
        
        if current_time - self.last_detection_time < self.detection_cooldown:
            return None
        
        result = self.detect_product(frame)
        
        if result["detected"] and result["product_type"] != "unknown":
            self.last_detection_time = current_time
            self.detection_count[result["product_type"]] += 1
            
            print(f"\n{'='*50}")
            print(f"ğŸ“¦ æ£€æµ‹åˆ°äº§å“!")
            print(f"   ç±»å‹: {result['product_type']}")
            print(f"   é¢œè‰²: {result['color']}")
            print(f"   å½¢çŠ¶: {result['shape']}")
            print(f"   ç½®ä¿¡åº¦: {result['confidence']:.0%}")
            print(f"{'='*50}\n")
            
            return result
        
        return None


class ProductDetectionServer:
    """äº§å“æ£€æµ‹æœåŠ¡å™¨é€šä¿¡"""
    
    def __init__(self, server_url: str, device_id: str):
        self.server_url = server_url.rstrip('/')
        self.device_id = device_id
    
    def report_product_detection(self, result: Dict) -> bool:
        """ä¸ŠæŠ¥äº§å“æ£€æµ‹ç»“æœ"""
        try:
            data = {
                "device_id": self.device_id,
                "product_type": result["product_type"],
                "color": result["color"],
                "shape": result["shape"],
                "confidence": result["confidence"],
                "timestamp": datetime.now().isoformat()
            }
            
            response = requests.post(
                f"{self.server_url}/api/product/detection",
                json=data,
                timeout=2
            )
            return response.status_code == 200
        except Exception as e:
            print(f"ä¸ŠæŠ¥å¤±è´¥: {e}")
            return False
    
    def send_video_frame(self, frame: np.ndarray, detection_info: Dict = None) -> bool:
        """å‘é€è§†é¢‘å¸§"""
        try:
            encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), VIDEO_QUALITY]
            _, buffer = cv2.imencode('.jpg', frame, encode_param)
            frame_base64 = base64.b64encode(buffer).decode('utf-8')
            
            data = {
                "device_id": self.device_id,
                "frame": frame_base64,
                "timestamp": datetime.now().isoformat(),
                "detection_type": "product",
                "detection": detection_info
            }
            
            response = requests.post(
                f"{self.server_url}/api/video/frame",
                json=data,
                timeout=1
            )
            return response.status_code == 200
        except Exception:
            return False


def run_product_detection(camera_id: int = 0, 
                          camera_width: int = 640, 
                          camera_height: int = 480,
                          headless: bool = False):
    """
    è¿è¡Œäº§å“æ£€æµ‹
    
    Args:
        camera_id: æ‘„åƒå¤´ID
        camera_width: æ‘„åƒå¤´å®½åº¦
        camera_height: æ‘„åƒå¤´é«˜åº¦
        headless: æ˜¯å¦æ— å¤´æ¨¡å¼ï¼ˆæ— GUIï¼‰
    """
    # åˆå§‹åŒ–æ£€æµ‹å™¨
    detector = ProductDetector()
    
    # åˆå§‹åŒ–æœåŠ¡å™¨å®¢æˆ·ç«¯
    server = None
    if ENABLE_SERVER_REPORT:
        server = ProductDetectionServer(SERVER_URL, DEVICE_ID)
        print(f"âœ“ æœåŠ¡å™¨å®¢æˆ·ç«¯å·²åˆå§‹åŒ–: {SERVER_URL}")
    
    # æ‰“å¼€æ‘„åƒå¤´
    cap = cv2.VideoCapture(camera_id)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, camera_width)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, camera_height)
    cap.set(cv2.CAP_PROP_FPS, 30)
    
    if not cap.isOpened():
        print("é”™è¯¯ï¼šæ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        return
    
    print("\n" + "="*60)
    print("ğŸ” äº§å“æ£€æµ‹ç³»ç»Ÿå·²å¯åŠ¨")
    print(f"ğŸ“¹ æ‘„åƒå¤´: {camera_id} | åˆ†è¾¨ç‡: {camera_width}x{camera_height}")
    print("ğŸ“¦ äº§å“A: è“è‰²æ–¹å½¢")
    print("ğŸ“¦ äº§å“B: é’è‰²åœ†å½¢")
    print("-"*60)
    print("æ“ä½œè¯´æ˜:")
    print("  'c' - æ‰‹åŠ¨æ•è·æ£€æµ‹")
    print("  'r' - é‡ç½®è®¡æ•°")
    print("  'q' - é€€å‡ºç¨‹åº")
    print("="*60 + "\n")
    
    window_name = "Product Detection"
    if not headless:
        cv2.namedWindow(window_name)
    
    last_stream_time = 0
    stream_interval = 1.0 / VIDEO_STREAM_FPS
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                print("é”™è¯¯ï¼šæ— æ³•è¯»å–å¸§")
                break
            
            # å®æ—¶æ£€æµ‹ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
            result = detector.detect_product(frame)
            
            # ç»˜åˆ¶æ£€æµ‹ç»“æœ
            display_frame = detector.draw_detection(frame, result)
            
            # æ¨é€è§†é¢‘æµ
            current_time = time.time()
            if ENABLE_VIDEO_STREAM and server and current_time - last_stream_time >= stream_interval:
                last_stream_time = current_time
                detection_info = {
                    "product_type": result.get("product_type", "unknown"),
                    "detected": result.get("detected", False)
                } if result["detected"] else None
                
                def _stream():
                    server.send_video_frame(display_frame, detection_info)
                thread = threading.Thread(target=_stream)
                thread.daemon = True
                thread.start()
            
            if not headless:
                cv2.imshow(window_name, display_frame)
                key = cv2.waitKey(1) & 0xFF
                
                if key == ord('q'):
                    print("\næ­£åœ¨é€€å‡º...")
                    break
                elif key == ord('c'):
                    # æ‰‹åŠ¨æ•è·æ£€æµ‹
                    capture_result = detector.capture_and_detect(frame)
                    if capture_result and server:
                        def _report():
                            server.report_product_detection(capture_result)
                        thread = threading.Thread(target=_report)
                        thread.daemon = True
                        thread.start()
                elif key == ord('r'):
                    # é‡ç½®è®¡æ•°
                    detector.detection_count = {"product_a": 0, "product_b": 0, "unknown": 0}
                    print("âœ“ è®¡æ•°å·²é‡ç½®")
            else:
                time.sleep(0.01)
                
    except KeyboardInterrupt:
        print("\n\næ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...")
    finally:
        cap.release()
        if not headless:
            cv2.destroyAllWindows()
        print("âœ“ ç¨‹åºå·²å®‰å…¨é€€å‡º")
        print(f"\næ£€æµ‹ç»Ÿè®¡:")
        print(f"  äº§å“A: {detector.detection_count['product_a']}")
        print(f"  äº§å“B: {detector.detection_count['product_b']}")


if __name__ == "__main__":
    run_product_detection(
        camera_id=0,
        camera_width=640,
        camera_height=480,
        headless=False
    )
