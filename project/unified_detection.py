"""
ç»Ÿä¸€æ£€æµ‹ç³»ç»Ÿ - æ•´åˆå±é™©åŒºåŸŸæ£€æµ‹å’Œäº§å“æ£€æµ‹
åŠŸèƒ½ï¼š
1. é»˜è®¤è¿è¡Œå±é™©åŒºåŸŸæ£€æµ‹ï¼ˆäººå‘˜å®‰å…¨ç›‘æ§ï¼‰
2. æ”¯æŒåˆ‡æ¢åˆ°äº§å“æ£€æµ‹æ¨¡å¼ï¼ˆé¢œè‰²/å½¢çŠ¶è¯†åˆ«ï¼‰
3. é€šè¿‡åç«¯APIæˆ–é”®ç›˜æ§åˆ¶æ¨¡å¼åˆ‡æ¢
4. å…±äº«åŒä¸€ä¸ªæ‘„åƒå¤´ï¼Œé¿å…èµ„æºå†²çª
5. äººå‘˜è¿›å…¥/ç¦»å¼€å±é™©åŒºåŸŸçš„çŠ¶æ€è¿½è¸ªå’Œç»Ÿè®¡

é€‚ç”¨äºï¼šæ ‘è“æ´¾ / Windows ç¬”è®°æœ¬
"""

import cv2
import numpy as np
from ultralytics import YOLO
from datetime import datetime
from dataclasses import dataclass, field
from typing import List, Tuple, Callable, Optional, Dict, Set
from enum import Enum
import time
import threading
import platform
import subprocess
import base64
import requests
import uuid

# ==================== ç³»ç»Ÿæ£€æµ‹ ====================
IS_WINDOWS = platform.system() == "Windows"
IS_LINUX = platform.system() == "Linux"

if IS_WINDOWS:
    import winsound

# å°è¯•å¯¼å…¥ picamera2ï¼ˆæ ‘è“æ´¾CSIæ‘„åƒå¤´ï¼‰
PICAMERA2_AVAILABLE = False
if IS_LINUX:
    try:
        from picamera2 import Picamera2
        PICAMERA2_AVAILABLE = True
        print("âœ“ picamera2 å¯ç”¨")
    except ImportError:
        print("âš ï¸ picamera2 ä¸å¯ç”¨ï¼Œå°†å°è¯•å…¶ä»–æ–¹å¼æ‰“å¼€æ‘„åƒå¤´")

# ==================== é…ç½® ====================
#SERVER_URL = "http://localhost:8000"
"æ ‘è“æ´¾ä½¿ç”¨"
SERVER_URL = "http://192.168.137.1:8000"

DEVICE_ID = "device_001"
ENABLE_SERVER_REPORT = True
ENABLE_VIDEO_STREAM = True
VIDEO_STREAM_FPS = 10
VIDEO_QUALITY = 50

# æ ‘è“æ´¾ä¼˜åŒ–ï¼šé™ä½åˆ†è¾¨ç‡æé«˜å¸§ç‡
CAMERA_WIDTH = 480
CAMERA_HEIGHT = 360


class DetectionMode(Enum):
    """æ£€æµ‹æ¨¡å¼"""
    ZONE = "zone"           # å±é™©åŒºåŸŸæ£€æµ‹
    PRODUCT = "product"     # äº§å“æ£€æµ‹


class PersonState(Enum):
    """äººå‘˜çŠ¶æ€"""
    SAFE = "safe"           # åœ¨å®‰å…¨åŒº
    DANGER = "danger"       # åœ¨å±é™©åŒº
    UNKNOWN = "unknown"     # æœªçŸ¥


@dataclass
class TrackedPerson:
    """è¿½è¸ªçš„äººå‘˜ä¿¡æ¯"""
    track_id: str                    # è¿½è¸ªID
    bbox: Tuple[int, int, int, int]  # è¾¹ç•Œæ¡†
    center: Tuple[int, int]          # ä¸­å¿ƒç‚¹
    state: PersonState               # å½“å‰çŠ¶æ€
    last_seen: float                 # æœ€åä¸€æ¬¡çœ‹åˆ°çš„æ—¶é—´
    entered_danger_time: float = 0   # è¿›å…¥å±é™©åŒºçš„æ—¶é—´
    
    def update(self, bbox: Tuple[int, int, int, int], center: Tuple[int, int], state: PersonState):
        """æ›´æ–°äººå‘˜ä¿¡æ¯"""
        self.bbox = bbox
        self.center = center
        self.state = state
        self.last_seen = time.time()


@dataclass
class ZoneStatistics:
    """å±é™©åŒºåŸŸç»Ÿè®¡ä¿¡æ¯"""
    total_entries: int = 0           # æ€»è¿›å…¥æ¬¡æ•°
    total_exits: int = 0             # æ€»ç¦»å¼€æ¬¡æ•°
    current_in_danger: int = 0       # å½“å‰åœ¨å±é™©åŒºçš„äººæ•°
    persons_in_danger: Set[str] = field(default_factory=set)  # å½“å‰åœ¨å±é™©åŒºçš„äººå‘˜IDé›†åˆ
    
    def person_entered(self, track_id: str):
        """äººå‘˜è¿›å…¥å±é™©åŒº"""
        if track_id not in self.persons_in_danger:
            self.persons_in_danger.add(track_id)
            self.total_entries += 1
            self.current_in_danger = len(self.persons_in_danger)
            return True
        return False
    
    def person_exited(self, track_id: str):
        """äººå‘˜ç¦»å¼€å±é™©åŒº"""
        if track_id in self.persons_in_danger:
            self.persons_in_danger.discard(track_id)
            self.total_exits += 1
            self.current_in_danger = len(self.persons_in_danger)
            return True
        return False
    
    def remove_person(self, track_id: str):
        """ç§»é™¤äººå‘˜ï¼ˆç¦»å¼€ç”»é¢ï¼‰"""
        if track_id in self.persons_in_danger:
            self.persons_in_danger.discard(track_id)
            self.current_in_danger = len(self.persons_in_danger)
    
    def to_dict(self) -> dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "total_entries": self.total_entries,
            "total_exits": self.total_exits,
            "current_in_danger": self.current_in_danger
        }


@dataclass
class AlertInfo:
    """è­¦æŠ¥ä¿¡æ¯"""
    timestamp: str
    zone_type: str
    person_count: int
    message: str
    bbox: Tuple[int, int, int, int]
    event_type: str = "enter"  # enter=è¿›å…¥, exit=ç¦»å¼€


# ==================== æœåŠ¡å™¨é€šä¿¡ ====================
class ServerClient:
    """æœåŠ¡å™¨é€šä¿¡å®¢æˆ·ç«¯"""
    
    def __init__(self, server_url: str, device_id: str):
        self.server_url = server_url.rstrip('/')
        self.device_id = device_id
        self._current_mode = DetectionMode.ZONE
        self._mode_lock = threading.Lock()
    
    def get_detection_mode(self) -> DetectionMode:
        """ä»æœåŠ¡å™¨è·å–å½“å‰æ£€æµ‹æ¨¡å¼"""
        try:
            response = requests.get(
                f"{self.server_url}/api/detection/mode/{self.device_id}",
                timeout=1
            )
            if response.status_code == 200:
                data = response.json()
                mode_str = data.get("mode", "zone")
                return DetectionMode.PRODUCT if mode_str == "product" else DetectionMode.ZONE
        except Exception:
            pass
        return self._current_mode
    
    def report_detection(self, person_count: int, in_danger_zone: bool, alert_triggered: bool):
        """ä¸ŠæŠ¥å±é™©åŒºåŸŸæ£€æµ‹ç»“æœ"""
        try:
            data = {
                "device_id": self.device_id,
                "person_count": person_count,
                "in_danger_zone": in_danger_zone,
                "alert_triggered": alert_triggered
            }
            requests.post(f"{self.server_url}/api/detection", json=data, timeout=2)
        except Exception:
            pass
    
    def report_zone_event(self, event_type: str, statistics: dict, message: str):
        """
        ä¸ŠæŠ¥å±é™©åŒºåŸŸäº‹ä»¶ï¼ˆè¿›å…¥/ç¦»å¼€ï¼‰
        
        Args:
            event_type: äº‹ä»¶ç±»å‹ (enter/exit)
            statistics: ç»Ÿè®¡ä¿¡æ¯
            message: äº‹ä»¶æ¶ˆæ¯
        """
        try:
            data = {
                "device_id": self.device_id,
                "event_type": event_type,
                "statistics": statistics,
                "message": message,
                "timestamp": datetime.now().isoformat()
            }
            requests.post(f"{self.server_url}/api/zone/event", json=data, timeout=2)
        except Exception:
            pass
    
    def report_product(self, result: Dict):
        """ä¸ŠæŠ¥äº§å“æ£€æµ‹ç»“æœ"""
        try:
            data = {
                "device_id": self.device_id,
                "product_type": result.get("product_type", "unknown"),
                "color": result.get("color", ""),
                "shape": result.get("shape", ""),
                "confidence": result.get("confidence", 0),
                "timestamp": datetime.now().isoformat()
            }
            requests.post(f"{self.server_url}/api/product/detection", json=data, timeout=2)
        except Exception:
            pass
    
    def send_video_frame(self, frame: np.ndarray, detection_info: dict = None):
        """å‘é€è§†é¢‘å¸§"""
        try:
            encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), VIDEO_QUALITY]
            _, buffer = cv2.imencode('.jpg', frame, encode_param)
            frame_base64 = base64.b64encode(buffer).decode('utf-8')
            
            data = {
                "device_id": self.device_id,
                "frame": frame_base64,
                "timestamp": datetime.now().isoformat(),
                "detection": detection_info
            }
            requests.post(f"{self.server_url}/api/video/frame", json=data, timeout=1)
        except Exception:
            pass


# ==================== äººå‘˜è¿½è¸ªå™¨ ====================
class PersonTracker:
    """
    ç®€å•çš„äººå‘˜è¿½è¸ªå™¨ - åŸºäºä½ç½®åŒ¹é…
    ç”¨äºè¿½è¸ªäººå‘˜çš„è¿›å…¥/ç¦»å¼€å±é™©åŒºåŸŸçŠ¶æ€
    """
    
    def __init__(self, max_distance: float = 100, timeout: float = 2.0):
        """
        Args:
            max_distance: æœ€å¤§åŒ¹é…è·ç¦»ï¼ˆåƒç´ ï¼‰
            timeout: äººå‘˜æ¶ˆå¤±è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.tracked_persons: Dict[str, TrackedPerson] = {}
        self.max_distance = max_distance
        self.timeout = timeout
        self.next_id = 0
    
    def _generate_id(self) -> str:
        """ç”Ÿæˆå”¯ä¸€ID"""
        self.next_id += 1
        return f"person_{self.next_id}"
    
    def _calculate_distance(self, p1: Tuple[int, int], p2: Tuple[int, int]) -> float:
        """è®¡ç®—ä¸¤ç‚¹è·ç¦»"""
        return np.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)
    
    def _find_best_match(self, center: Tuple[int, int]) -> Optional[str]:
        """æ‰¾åˆ°æœ€ä½³åŒ¹é…çš„å·²è¿½è¸ªäººå‘˜"""
        best_match = None
        best_distance = self.max_distance
        
        for track_id, person in self.tracked_persons.items():
            distance = self._calculate_distance(center, person.center)
            if distance < best_distance:
                best_distance = distance
                best_match = track_id
        
        return best_match
    
    def update(self, detections: List[Tuple[int, int, int, int, float]], 
               get_state_func: Callable[[Tuple[int, int]], PersonState]) -> List[dict]:
        """
        æ›´æ–°è¿½è¸ªçŠ¶æ€
        
        Args:
            detections: æ£€æµ‹ç»“æœåˆ—è¡¨ [(x1, y1, x2, y2, conf), ...]
            get_state_func: è·å–äººå‘˜çŠ¶æ€çš„å‡½æ•°ï¼ˆæ ¹æ®ä¸­å¿ƒç‚¹åˆ¤æ–­æ˜¯å¦åœ¨å±é™©åŒºï¼‰
        
        Returns:
            çŠ¶æ€å˜åŒ–äº‹ä»¶åˆ—è¡¨ [{"track_id": str, "event": "enter"/"exit", "bbox": tuple}, ...]
        """
        events = []
        current_time = time.time()
        matched_ids = set()
        
        # å¤„ç†æ¯ä¸ªæ£€æµ‹ç»“æœ
        for detection in detections:
            x1, y1, x2, y2, conf = detection
            bbox = (x1, y1, x2, y2)
            center = (int((x1 + x2) / 2), int(y2))  # ä½¿ç”¨è„šéƒ¨ä¸­å¿ƒç‚¹
            current_state = get_state_func(center)
            
            # å°è¯•åŒ¹é…å·²æœ‰äººå‘˜
            match_id = self._find_best_match(center)
            
            if match_id and match_id not in matched_ids:
                # åŒ¹é…åˆ°å·²æœ‰äººå‘˜ï¼Œæ£€æŸ¥çŠ¶æ€å˜åŒ–
                person = self.tracked_persons[match_id]
                old_state = person.state
                
                # çŠ¶æ€å˜åŒ–æ£€æµ‹
                if old_state != current_state:
                    if old_state == PersonState.SAFE and current_state == PersonState.DANGER:
                        # ä»å®‰å…¨åŒºè¿›å…¥å±é™©åŒº
                        events.append({
                            "track_id": match_id,
                            "event": "enter",
                            "bbox": bbox,
                            "center": center
                        })
                        person.entered_danger_time = current_time
                    elif old_state == PersonState.DANGER and current_state == PersonState.SAFE:
                        # ä»å±é™©åŒºç¦»å¼€åˆ°å®‰å…¨åŒº
                        events.append({
                            "track_id": match_id,
                            "event": "exit",
                            "bbox": bbox,
                            "center": center
                        })
                
                # æ›´æ–°äººå‘˜ä¿¡æ¯
                person.update(bbox, center, current_state)
                matched_ids.add(match_id)
            else:
                # æ–°äººå‘˜
                new_id = self._generate_id()
                new_person = TrackedPerson(
                    track_id=new_id,
                    bbox=bbox,
                    center=center,
                    state=current_state,
                    last_seen=current_time
                )
                self.tracked_persons[new_id] = new_person
                matched_ids.add(new_id)
                
                # å¦‚æœæ–°äººå‘˜ç›´æ¥å‡ºç°åœ¨å±é™©åŒºï¼Œä¹Ÿè§¦å‘è¿›å…¥äº‹ä»¶
                if current_state == PersonState.DANGER:
                    events.append({
                        "track_id": new_id,
                        "event": "enter",
                        "bbox": bbox,
                        "center": center
                    })
                    new_person.entered_danger_time = current_time
        
        # æ¸…ç†è¶…æ—¶çš„äººå‘˜
        expired_ids = []
        for track_id, person in self.tracked_persons.items():
            if track_id not in matched_ids:
                if current_time - person.last_seen > self.timeout:
                    expired_ids.append(track_id)
                    # å¦‚æœäººå‘˜åœ¨å±é™©åŒºæ¶ˆå¤±ï¼Œè§†ä¸ºç¦»å¼€
                    if person.state == PersonState.DANGER:
                        events.append({
                            "track_id": track_id,
                            "event": "exit_timeout",
                            "bbox": person.bbox,
                            "center": person.center
                        })
        
        for track_id in expired_ids:
            del self.tracked_persons[track_id]
        
        return events
    
    def get_persons_in_danger(self) -> List[TrackedPerson]:
        """è·å–å½“å‰åœ¨å±é™©åŒºçš„äººå‘˜åˆ—è¡¨"""
        return [p for p in self.tracked_persons.values() if p.state == PersonState.DANGER]
    
    def reset(self):
        """é‡ç½®è¿½è¸ªå™¨"""
        self.tracked_persons.clear()
        self.next_id = 0


# ==================== å±é™©åŒºåŸŸæ£€æµ‹å™¨ ====================
class ZoneDetector:
    """å±é™©åŒºåŸŸæ£€æµ‹å™¨ - åŸºäºYOLOv8ï¼Œæ”¯æŒäººå‘˜çŠ¶æ€è¿½è¸ª"""
    
    def __init__(self, model_path: str = "yolov8n_ncnn_model", frame_skip: int = 3,
                 input_size: Tuple[int, int] = (320, 320), alert_cooldown: float = 3.0):
        print("æ­£åœ¨åŠ è½½YOLOv8æ¨¡å‹...")
        self.model = YOLO(model_path)
        # NCNN æ¨¡å‹ä¸éœ€è¦ fuse()
        if model_path.endswith(".pt"):
            self.model.fuse()
        
        self.danger_zones: List[np.ndarray] = []
        self.safe_zones: List[np.ndarray] = []
        self.alert_callback: Optional[Callable] = None
        self.exit_callback: Optional[Callable] = None  # ç¦»å¼€å±é™©åŒºå›è°ƒ
        self.person_class_id = 0
        
        self.frame_skip = frame_skip
        self.frame_count = 0
        self.input_size = input_size
        self.alert_cooldown = alert_cooldown
        self.last_alert_time = {}
        self.last_detections = []
        self.scale_x = 1.0
        self.scale_y = 1.0
        
        # äººå‘˜è¿½è¸ªå™¨
        self.tracker = PersonTracker(max_distance=100, timeout=2.0)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.statistics = ZoneStatistics()
        
        print(f"âœ“ YOLOv8æ¨¡å‹åŠ è½½å®Œæˆ")
        print(f"âœ“ äººå‘˜è¿½è¸ªå™¨å·²å¯ç”¨")
    
    def add_danger_zone(self, points: List[Tuple[int, int]]):
        self.danger_zones.append(np.array(points, dtype=np.int32))
    
    def add_safe_zone(self, points: List[Tuple[int, int]]):
        self.safe_zones.append(np.array(points, dtype=np.int32))
    
    def set_alert_callback(self, callback: Callable):
        """è®¾ç½®è¿›å…¥å±é™©åŒºæŠ¥è­¦å›è°ƒ"""
        self.alert_callback = callback
    
    def set_exit_callback(self, callback: Callable):
        """è®¾ç½®ç¦»å¼€å±é™©åŒºé€šçŸ¥å›è°ƒ"""
        self.exit_callback = callback
    
    def _point_in_zone(self, point: Tuple[int, int], zone: np.ndarray) -> bool:
        return cv2.pointPolygonTest(zone, point, False) >= 0
    
    def _get_person_center(self, bbox: Tuple[int, int, int, int]) -> Tuple[int, int]:
        x1, y1, x2, y2 = bbox
        return (int((x1 + x2) / 2), int(y2))
    
    def _get_person_state(self, center: Tuple[int, int]) -> PersonState:
        """æ ¹æ®ä¸­å¿ƒç‚¹åˆ¤æ–­äººå‘˜çŠ¶æ€"""
        for zone in self.danger_zones:
            if self._point_in_zone(center, zone):
                return PersonState.DANGER
        for zone in self.safe_zones:
            if self._point_in_zone(center, zone):
                return PersonState.SAFE
        return PersonState.UNKNOWN
    
    def get_statistics(self) -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return self.statistics.to_dict()
    
    def reset_statistics(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.statistics = ZoneStatistics()
        self.tracker.reset()
        print("âœ“ ç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®")
    
    def detect(self, frame: np.ndarray, conf_threshold: float = 0.5) -> Tuple[np.ndarray, dict]:
        """æ‰§è¡Œå±é™©åŒºåŸŸæ£€æµ‹ï¼ˆå¼‚æ­¥æ¨¡å¼ä¸‹æ¯æ¬¡è°ƒç”¨éƒ½æ‰§è¡Œæ£€æµ‹ï¼‰"""
        h_orig, w_orig = frame.shape[:2]
        output = frame.copy()
        
        events = []  # çŠ¶æ€å˜åŒ–äº‹ä»¶
        
        # YOLOæ£€æµ‹ - å¼‚æ­¥æ¨¡å¼ä¸‹æ¯æ¬¡éƒ½æ‰§è¡Œ
        if self.input_size:
            resized = cv2.resize(frame, self.input_size)
            self.scale_x = w_orig / self.input_size[0]
            self.scale_y = h_orig / self.input_size[1]
        else:
            resized = frame
            self.scale_x = self.scale_y = 1.0
        
        results = self.model(resized, conf=conf_threshold, classes=[self.person_class_id],
                           verbose=False, device='cpu')
        
        self.last_detections = []
        for result in results:
            for box in result.boxes:
                x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
                conf = float(box.conf[0])
                x1, y1 = int(x1 * self.scale_x), int(y1 * self.scale_y)
                x2, y2 = int(x2 * self.scale_x), int(y2 * self.scale_y)
                self.last_detections.append((x1, y1, x2, y2, conf))
        
        # æ›´æ–°è¿½è¸ªå™¨å¹¶è·å–çŠ¶æ€å˜åŒ–äº‹ä»¶
        events = self.tracker.update(self.last_detections, self._get_person_state)
        
        # å¤„ç†çŠ¶æ€å˜åŒ–äº‹ä»¶
        for event in events:
            track_id = event["track_id"]
            event_type = event["event"]
            bbox = event["bbox"]
            
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            if event_type == "enter":
                # è¿›å…¥å±é™©åŒº
                self.statistics.person_entered(track_id)
                if self.alert_callback:
                    alert = AlertInfo(
                        timestamp=timestamp,
                        zone_type="danger",
                        person_count=self.statistics.current_in_danger,
                        message=f"âš ï¸ äººå‘˜è¿›å…¥å±é™©åŒºåŸŸï¼å½“å‰å±é™©åŒºäººæ•°: {self.statistics.current_in_danger}",
                        bbox=bbox,
                        event_type="enter"
                    )
                    self.alert_callback(alert)
            
            elif event_type in ["exit", "exit_timeout"]:
                # ç¦»å¼€å±é™©åŒº
                self.statistics.person_exited(track_id)
                if self.exit_callback:
                    alert = AlertInfo(
                        timestamp=timestamp,
                        zone_type="safe",
                        person_count=self.statistics.current_in_danger,
                        message=f"âœ… äººå‘˜ç¦»å¼€å±é™©åŒºåŸŸï¼å½“å‰å±é™©åŒºäººæ•°: {self.statistics.current_in_danger}",
                        bbox=bbox,
                        event_type="exit"
                    )
                    self.exit_callback(alert)
        
        # ç»˜åˆ¶åŒºåŸŸ
        overlay = output.copy()
        for zone in self.danger_zones:
            cv2.fillPoly(overlay, [zone], (0, 0, 200))
            cv2.polylines(output, [zone], True, (0, 0, 255), 2)
        for zone in self.safe_zones:
            cv2.fillPoly(overlay, [zone], (0, 200, 0))
            cv2.polylines(output, [zone], True, (0, 255, 0), 2)
        cv2.addWeighted(overlay, 0.3, output, 0.7, 0, output)
        
        # ç»˜åˆ¶è­¦æˆ’çº¿
        mid_x = w_orig // 2
        cv2.line(output, (mid_x, 0), (mid_x, h_orig), (0, 255, 255), 2)
        cv2.putText(output, "WARNING LINE", (mid_x + 10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        # å¤„ç†æ£€æµ‹ç»“æœå¹¶ç»˜åˆ¶
        danger_count = 0
        person_count = len(self.last_detections)
        
        for detection in self.last_detections:
            x1, y1, x2, y2, conf = detection
            center = self._get_person_center((x1, y1, x2, y2))
            in_danger = any(self._point_in_zone(center, zone) for zone in self.danger_zones)
            
            if in_danger:
                danger_count += 1
                color = (0, 0, 255)
                label = "DANGER!"
            else:
                color = (0, 255, 0)
                label = "Person"
            
            cv2.rectangle(output, (x1, y1), (x2, y2), color, 2)
            cv2.putText(output, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
            cv2.circle(output, center, 4, color, -1)
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = self.statistics
        y_offset = 30
        
        # è­¦å‘Šä¿¡æ¯
        if stats.current_in_danger > 0:
            cv2.putText(output, f"WARNING: {stats.current_in_danger} in DANGER ZONE!", (10, y_offset),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
            y_offset += 30
        
        # ç»Ÿè®¡ä¿¡æ¯
        cv2.putText(output, f"Persons: {person_count}", (10, y_offset),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        y_offset += 25
        
        cv2.putText(output, f"In Danger: {stats.current_in_danger}", (10, y_offset),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
        y_offset += 25
        
        cv2.putText(output, f"Entries: {stats.total_entries} | Exits: {stats.total_exits}", (10, y_offset),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 200, 100), 1)
        
        # æ¨¡å¼æ ‡è¯†
        cv2.putText(output, "[ZONE MODE]", (w_orig - 150, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        detection_info = {
            "mode": "zone",
            "person_count": person_count,
            "in_danger_zone": stats.current_in_danger > 0,
            "alert_triggered": len([e for e in events if e["event"] == "enter"]) > 0,
            "exit_triggered": len([e for e in events if e["event"] in ["exit", "exit_timeout"]]) > 0,
            "statistics": stats.to_dict(),
            "events": events
        }
        
        return output, detection_info


# ==================== äº§å“æ£€æµ‹å™¨ ====================
class ProductDetector:
    """äº§å“æ£€æµ‹å™¨ - åŸºäºé¢œè‰²å’Œå½¢çŠ¶"""
    
    COLOR_RANGES = {
        "product_a": {
            "lower": np.array([100, 100, 100]),
            "upper": np.array([130, 255, 255]),
            "name": "è“è‰²",
            "display_color": (255, 150, 50)
        },
        "product_b": {
            "lower": np.array([75, 100, 100]),
            "upper": np.array([95, 255, 255]),
            "name": "é’è‰²",
            "display_color": (200, 200, 50)
        }
    }
    
    SHAPE_CIRCULARITY_THRESHOLD = 0.7
    MIN_CONTOUR_AREA = 1000
    MAX_CONTOUR_AREA = 100000
    
    def __init__(self):
        self.detection_count = {"product_a": 0, "product_b": 0, "unknown": 0}
        self.last_detection_time = 0
        self.detection_cooldown = 1.0
        print("âœ“ äº§å“æ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def detect_color(self, frame: np.ndarray) -> Tuple[str, np.ndarray]:
        """æ£€æµ‹é¢œè‰²"""
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        best_match = "unknown"
        best_area = 0
        best_mask = None
        
        for product_type, color_range in self.COLOR_RANGES.items():
            mask = cv2.inRange(hsv, color_range["lower"], color_range["upper"])
            kernel = np.ones((5, 5), np.uint8)
            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
            area = cv2.countNonZero(mask)
            
            if area > best_area and area > self.MIN_CONTOUR_AREA:
                best_area = area
                best_match = product_type
                best_mask = mask
        
        return best_match, best_mask if best_mask is not None else np.zeros_like(frame[:,:,0])
    
    def detect_shape(self, mask: np.ndarray) -> Tuple[str, List[np.ndarray]]:
        """æ£€æµ‹å½¢çŠ¶"""
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not contours:
            return "unknown", []
        
        valid_contours = [c for c in contours
                        if self.MIN_CONTOUR_AREA < cv2.contourArea(c) < self.MAX_CONTOUR_AREA]
        if not valid_contours:
            return "unknown", []
        
        largest = max(valid_contours, key=cv2.contourArea)
        area = cv2.contourArea(largest)
        perimeter = cv2.arcLength(largest, True)
        
        if perimeter == 0:
            return "unknown", valid_contours
        
        circularity = 4 * np.pi * area / (perimeter * perimeter)
        shape = "circle" if circularity > self.SHAPE_CIRCULARITY_THRESHOLD else "rectangle"
        return shape, valid_contours
    
    def detect(self, frame: np.ndarray) -> Tuple[np.ndarray, dict]:
        """æ‰§è¡Œäº§å“æ£€æµ‹"""
        output = frame.copy()
        h, w = output.shape[:2]
        
        # é¢œè‰²æ£€æµ‹
        color_type, mask = self.detect_color(frame)
        
        # å½¢çŠ¶æ£€æµ‹
        shape_type, contours = self.detect_shape(mask)
        
        # ç»¼åˆåˆ¤æ–­
        result = {
            "mode": "product",
            "detected": False,
            "product_type": "unknown",
            "color": "unknown",
            "shape": "unknown",
            "confidence": 0.0
        }
        
        if color_type != "unknown" and shape_type != "unknown":
            if color_type == "product_a" and shape_type == "rectangle":
                product_type, confidence = "product_a", 0.9
            elif color_type == "product_b" and shape_type == "circle":
                product_type, confidence = "product_b", 0.9
            elif color_type in ["product_a", "product_b"]:
                product_type, confidence = color_type, 0.7
            else:
                product_type, confidence = "unknown", 0.3
            
            result.update({
                "detected": True,
                "product_type": product_type,
                "color": self.COLOR_RANGES.get(color_type, {}).get("name", "æœªçŸ¥"),
                "shape": "åœ†å½¢" if shape_type == "circle" else "æ–¹å½¢",
                "confidence": confidence
            })
            
            # ç»˜åˆ¶è½®å»“
            if contours:
                color = self.COLOR_RANGES.get(color_type, {}).get("display_color", (128, 128, 128))
                cv2.drawContours(output, contours, -1, color, 3)
                
                largest = max(contours, key=cv2.contourArea)
                x, y, bw, bh = cv2.boundingRect(largest)
                cv2.rectangle(output, (x, y), (x+bw, y+bh), color, 2)
                
                label = f"Product {'A' if product_type == 'product_a' else 'B'}"
                cv2.putText(output, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
                cv2.putText(output, f"Conf: {confidence:.0%}", (x, y+bh+20),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
        
        # ç»˜åˆ¶æ£€æµ‹åŒºåŸŸ
        cv2.rectangle(output, (50, 50), (w-50, h-50), (100, 100, 100), 2)
        cv2.putText(output, "Detection Area", (55, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (100, 100, 100), 1)
        
        # ç»Ÿè®¡ä¿¡æ¯
        cv2.putText(output, f"Product A: {self.detection_count['product_a']}", (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, self.COLOR_RANGES["product_a"]["display_color"], 2)
        cv2.putText(output, f"Product B: {self.detection_count['product_b']}", (10, 55),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, self.COLOR_RANGES["product_b"]["display_color"], 2)
        
        # æ¨¡å¼æ ‡è¯†
        cv2.putText(output, "[PRODUCT MODE]", (w - 180, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 150, 50), 2)
        
        return output, result
    
    def capture(self, frame: np.ndarray) -> Optional[dict]:
        """æ‰‹åŠ¨æ•è·æ£€æµ‹"""
        current_time = time.time()
        if current_time - self.last_detection_time < self.detection_cooldown:
            return None
        
        _, result = self.detect(frame)
        if result["detected"] and result["product_type"] != "unknown":
            self.last_detection_time = current_time
            self.detection_count[result["product_type"]] += 1
            print(f"\nğŸ“¦ æ£€æµ‹åˆ°äº§å“: {result['product_type']} | {result['color']} | {result['shape']}")
            return result
        return None
    
    def reset_count(self):
        """é‡ç½®è®¡æ•°"""
        self.detection_count = {"product_a": 0, "product_b": 0, "unknown": 0}
        print("âœ“ äº§å“è®¡æ•°å·²é‡ç½®")



# ==================== GPIOæ§åˆ¶å™¨ ====================
class GPIOController:
    """GPIOæ§åˆ¶å™¨ - ç®¡ç†LEDå’Œèœ‚é¸£å™¨"""
    
    def __init__(self, led_pin: int = 16, buzzer_pin: int = 18):
        self.led_pin = led_pin
        self.buzzer_pin = buzzer_pin
        self.gpio_initialized = False
        self.led_state = False
        
        if IS_LINUX:
            try:
                import RPi.GPIO as GPIO
                self.GPIO = GPIO
                GPIO.setmode(GPIO.BCM)
                GPIO.setwarnings(False)
                GPIO.setup(self.led_pin, GPIO.OUT)
                GPIO.output(self.led_pin, GPIO.LOW)
                GPIO.setup(self.buzzer_pin, GPIO.OUT)
                GPIO.output(self.buzzer_pin, GPIO.LOW)
                self.gpio_initialized = True
                print(f"âœ“ GPIOåˆå§‹åŒ–æˆåŠŸ | LED: {led_pin} | èœ‚é¸£å™¨: {buzzer_pin}")
            except ImportError:
                print("âš ï¸ RPi.GPIOæœªå®‰è£…ï¼ŒGPIOåŠŸèƒ½ç¦ç”¨")
            except Exception as e:
                print(f"âš ï¸ GPIOåˆå§‹åŒ–å¤±è´¥: {e}")
    
    def turn_on_led(self):
        if self.gpio_initialized and not self.led_state:
            self.GPIO.output(self.led_pin, self.GPIO.HIGH)
            self.led_state = True
    
    def turn_off_led(self):
        if self.gpio_initialized and self.led_state:
            self.GPIO.output(self.led_pin, self.GPIO.LOW)
            self.led_state = False
    
    def buzzer_beep(self, duration: float = 0.5):
        if self.gpio_initialized:
            self.GPIO.output(self.buzzer_pin, self.GPIO.HIGH)
            time.sleep(duration)
            self.GPIO.output(self.buzzer_pin, self.GPIO.LOW)
    
    def cleanup(self):
        if self.gpio_initialized:
            self.GPIO.cleanup()
            print("âœ“ GPIOèµ„æºå·²æ¸…ç†")


# ==================== ç»Ÿä¸€æ£€æµ‹ç³»ç»Ÿ ====================
class UnifiedDetectionSystem:
    """
    ç»Ÿä¸€æ£€æµ‹ç³»ç»Ÿ - æ•´åˆå±é™©åŒºåŸŸæ£€æµ‹å’Œäº§å“æ£€æµ‹
    
    ç‰¹ç‚¹ï¼š
    1. å…±äº«åŒä¸€ä¸ªæ‘„åƒå¤´
    2. æ”¯æŒæ¨¡å¼åˆ‡æ¢ï¼ˆé”®ç›˜/åç«¯APIï¼‰
    3. é»˜è®¤è¿è¡Œå±é™©åŒºåŸŸæ£€æµ‹
    4. æŒ‰éœ€åˆ‡æ¢åˆ°äº§å“æ£€æµ‹
    5. äººå‘˜è¿›å…¥/ç¦»å¼€å±é™©åŒºåŸŸçš„çŠ¶æ€è¿½è¸ªå’Œç»Ÿè®¡
    6. å¼‚æ­¥æ£€æµ‹ï¼šä¸»çº¿ç¨‹æ˜¾ç¤ºç”»é¢ï¼Œæ£€æµ‹çº¿ç¨‹ç‹¬ç«‹è¿è¡Œï¼ˆæ ‘è“æ´¾ä¼˜åŒ–ï¼‰
    """
    
    def __init__(self, camera_id: int = 0):
        self.camera_id = camera_id
        self.cap = None
        
        # å½“å‰æ¨¡å¼
        self.current_mode = DetectionMode.ZONE
        self.mode_lock = threading.Lock()
        
        # æ£€æµ‹å™¨
        self.zone_detector = None
        self.product_detector = None
        
        # æœåŠ¡å™¨å®¢æˆ·ç«¯
        self.server = None
        if ENABLE_SERVER_REPORT or ENABLE_VIDEO_STREAM:
            self.server = ServerClient(SERVER_URL, DEVICE_ID)
        
        # GPIOæ§åˆ¶å™¨
        self.gpio = GPIOController()
        
        # è§†é¢‘æµæ§åˆ¶
        self.last_stream_time = 0
        self.stream_interval = 1.0 / VIDEO_STREAM_FPS
        
        # è¿è¡ŒçŠ¶æ€
        self.running = False
        
        # æ¨¡å¼æ£€æŸ¥é—´éš”
        self.last_mode_check = 0
        self.mode_check_interval = 1.0  # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡
        
        # ========== å¼‚æ­¥æ£€æµ‹ç›¸å…³ ==========
        # ç”¨äºçº¿ç¨‹é—´å…±äº«çš„å¸§å’Œæ£€æµ‹ç»“æœ
        self._frame_lock = threading.Lock()
        self._result_lock = threading.Lock()
        self._latest_frame = None           # æœ€æ–°çš„æ‘„åƒå¤´å¸§
        self._latest_result = None          # æœ€æ–°çš„æ£€æµ‹ç»“æœ
        self._latest_processed_frame = None # æœ€æ–°çš„å¤„ç†åå¸§ï¼ˆå¸¦æ ‡æ³¨ï¼‰
        self._detection_thread = None       # æ£€æµ‹çº¿ç¨‹
        self._detection_running = False     # æ£€æµ‹çº¿ç¨‹è¿è¡Œæ ‡å¿—
    
    def init_detectors(self):
        """åˆå§‹åŒ–æ£€æµ‹å™¨"""
        print("\n" + "="*60)
        print("ğŸš€ ç»Ÿä¸€æ£€æµ‹ç³»ç»Ÿåˆå§‹åŒ–ä¸­...")
        print("="*60)
        
        # åˆå§‹åŒ–å±é™©åŒºåŸŸæ£€æµ‹å™¨
        # å°è¯•ä½¿ç”¨NCNNæ¨¡å‹ï¼Œå¦‚æœä¸å¯ç”¨åˆ™å›é€€åˆ°PyTorchæ¨¡å‹
        import os
        if os.path.exists("yolov8n_ncnn_model"):
            model_path = "yolov8n_ncnn_model"
            print("âœ“ ä½¿ç”¨ NCNN æ ¼å¼æ¨¡å‹ï¼ˆARMä¼˜åŒ–ï¼‰")
        else:
            model_path = "yolov8n.pt"
            print("âš ï¸ NCNNæ¨¡å‹ä¸å¯ç”¨ï¼Œä½¿ç”¨ PyTorch æ¨¡å‹")
        
        self.zone_detector = ZoneDetector(
            model_path=model_path,
            frame_skip=1,
            input_size=(320, 320),
            alert_cooldown=3.0
        )
        
        # é…ç½®å±é™©åŒºåŸŸï¼ˆå±å¹•å³åŠéƒ¨åˆ†ï¼‰
        self.zone_detector.add_danger_zone([
            (CAMERA_WIDTH // 2, 0),
            (CAMERA_WIDTH, 0),
            (CAMERA_WIDTH, CAMERA_HEIGHT),
            (CAMERA_WIDTH // 2, CAMERA_HEIGHT)
        ])
        
        # é…ç½®å®‰å…¨åŒºåŸŸï¼ˆå±å¹•å·¦åŠéƒ¨åˆ†ï¼‰
        self.zone_detector.add_safe_zone([
            (0, 0),
            (CAMERA_WIDTH // 2, 0),
            (CAMERA_WIDTH // 2, CAMERA_HEIGHT),
            (0, CAMERA_HEIGHT)
        ])
        
        # è®¾ç½®è¿›å…¥å±é™©åŒºæŠ¥è­¦å›è°ƒ
        self.zone_detector.set_alert_callback(self._on_zone_enter)
        
        # è®¾ç½®ç¦»å¼€å±é™©åŒºé€šçŸ¥å›è°ƒ
        self.zone_detector.set_exit_callback(self._on_zone_exit)
        
        # åˆå§‹åŒ–äº§å“æ£€æµ‹å™¨
        self.product_detector = ProductDetector()
        
        print("âœ“ æ‰€æœ‰æ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
        print("âœ“ äººå‘˜çŠ¶æ€è¿½è¸ªå·²å¯ç”¨ï¼ˆè¿›å…¥/ç¦»å¼€å±é™©åŒºåŸŸï¼‰")
    
    def _on_zone_enter(self, alert: AlertInfo):
        """äººå‘˜è¿›å…¥å±é™©åŒºåŸŸå›è°ƒ"""
        print(f"\nğŸš¨ {alert.timestamp} - {alert.message}")
        print(f"   ğŸ“Š ç»Ÿè®¡: è¿›å…¥{self.zone_detector.statistics.total_entries}æ¬¡ | "
              f"ç¦»å¼€{self.zone_detector.statistics.total_exits}æ¬¡ | "
              f"å½“å‰{self.zone_detector.statistics.current_in_danger}äºº")
        
        # æ’­æ”¾æŠ¥è­¦å£°ï¼ˆè¿›å…¥å±é™©åŒº - é«˜é¢‘è­¦æŠ¥ï¼‰
        def _alarm():
            if IS_WINDOWS:
                winsound.Beep(1000, 500)  # é«˜é¢‘æŠ¥è­¦
            elif IS_LINUX:
                self.gpio.buzzer_beep(0.5)
        threading.Thread(target=_alarm, daemon=True).start()
        
        # LEDæŠ¥è­¦ï¼ˆçº¢ç¯é—ªçƒï¼‰
        def _led():
            self.gpio.turn_on_led()
            time.sleep(3.0)
            self.gpio.turn_off_led()
        threading.Thread(target=_led, daemon=True).start()
        
        # ä¸ŠæŠ¥åˆ°æœåŠ¡å™¨
        if self.server:
            def _report():
                self.server.report_zone_event(
                    event_type="enter",
                    statistics=self.zone_detector.get_statistics(),
                    message=alert.message
                )
            threading.Thread(target=_report, daemon=True).start()
    
    def _on_zone_exit(self, alert: AlertInfo):
        """äººå‘˜ç¦»å¼€å±é™©åŒºåŸŸå›è°ƒ"""
        print(f"\nâœ… {alert.timestamp} - {alert.message}")
        print(f"   ğŸ“Š ç»Ÿè®¡: è¿›å…¥{self.zone_detector.statistics.total_entries}æ¬¡ | "
              f"ç¦»å¼€{self.zone_detector.statistics.total_exits}æ¬¡ | "
              f"å½“å‰{self.zone_detector.statistics.current_in_danger}äºº")
        
        # æ’­æ”¾æç¤ºéŸ³ï¼ˆç¦»å¼€å±é™©åŒº - ä½é¢‘æç¤ºï¼‰
        def _notify():
            if IS_WINDOWS:
                winsound.Beep(500, 200)  # ä½é¢‘æç¤ºéŸ³
            elif IS_LINUX:
                self.gpio.buzzer_beep(0.2)
        threading.Thread(target=_notify, daemon=True).start()
        
        # ä¸ŠæŠ¥åˆ°æœåŠ¡å™¨
        if self.server:
            def _report():
                self.server.report_zone_event(
                    event_type="exit",
                    statistics=self.zone_detector.get_statistics(),
                    message=alert.message
                )
            threading.Thread(target=_report, daemon=True).start()
    
    def set_mode(self, mode: DetectionMode):
        """è®¾ç½®æ£€æµ‹æ¨¡å¼"""
        with self.mode_lock:
            if self.current_mode != mode:
                self.current_mode = mode
                mode_name = "å±é™©åŒºåŸŸæ£€æµ‹" if mode == DetectionMode.ZONE else "äº§å“æ£€æµ‹"
                print(f"\nğŸ”„ åˆ‡æ¢åˆ°: {mode_name}")
    
    def get_mode(self) -> DetectionMode:
        """è·å–å½“å‰æ¨¡å¼"""
        with self.mode_lock:
            return self.current_mode
    
    def _check_mode_from_server(self):
        """ä»æœåŠ¡å™¨æ£€æŸ¥æ¨¡å¼"""
        current_time = time.time()
        if current_time - self.last_mode_check >= self.mode_check_interval:
            self.last_mode_check = current_time
            if self.server:
                new_mode = self.server.get_detection_mode()
                self.set_mode(new_mode)
    
    def _stream_frame(self, frame: np.ndarray, detection_info: dict):
        """æ¨é€è§†é¢‘å¸§"""
        current_time = time.time()
        if current_time - self.last_stream_time >= self.stream_interval:
            self.last_stream_time = current_time
            if self.server:
                def _send():
                    self.server.send_video_frame(frame, detection_info)
                threading.Thread(target=_send, daemon=True).start()
    
    def _report_detection(self, detection_info: dict):
        """ä¸ŠæŠ¥æ£€æµ‹ç»“æœ"""
        if not self.server:
            return
        
        mode = detection_info.get("mode", "zone")
        
        if mode == "zone" and detection_info.get("alert_triggered"):
            def _report():
                self.server.report_detection(
                    detection_info.get("person_count", 0),
                    detection_info.get("in_danger_zone", False),
                    detection_info.get("alert_triggered", False)
                )
            threading.Thread(target=_report, daemon=True).start()
        
        elif mode == "product" and detection_info.get("detected"):
            def _report():
                self.server.report_product(detection_info)
            threading.Thread(target=_report, daemon=True).start()
    
    def _detection_worker(self):
        """
        å¼‚æ­¥æ£€æµ‹å·¥ä½œçº¿ç¨‹
        ç‹¬ç«‹è¿è¡ŒYOLOæ£€æµ‹ï¼Œä¸é˜»å¡ä¸»çº¿ç¨‹çš„ç”»é¢æ˜¾ç¤º
        """
        print("ğŸ”„ å¼‚æ­¥æ£€æµ‹çº¿ç¨‹å·²å¯åŠ¨")
        
        while self._detection_running:
            # è·å–æœ€æ–°å¸§
            with self._frame_lock:
                if self._latest_frame is None:
                    time.sleep(0.01)
                    continue
                frame = self._latest_frame.copy()
            
            # æ‰§è¡Œæ£€æµ‹ï¼ˆè¿™æ˜¯è€—æ—¶æ“ä½œï¼‰
            current_mode = self.get_mode()
            
            try:
                if current_mode == DetectionMode.ZONE:
                    processed_frame, detection_info = self.zone_detector.detect(frame)
                else:
                    processed_frame, detection_info = self.product_detector.detect(frame)
                
                # ä¿å­˜æ£€æµ‹ç»“æœ
                with self._result_lock:
                    self._latest_result = detection_info
                    self._latest_processed_frame = processed_frame
                
                # ä¸ŠæŠ¥æ£€æµ‹ç»“æœ
                self._report_detection(detection_info)
                
            except Exception as e:
                print(f"æ£€æµ‹çº¿ç¨‹é”™è¯¯: {e}")
                time.sleep(0.1)
        
        print("ğŸ”„ å¼‚æ­¥æ£€æµ‹çº¿ç¨‹å·²åœæ­¢")
    
    def _draw_overlay_on_frame(self, frame: np.ndarray) -> np.ndarray:
        """
        åœ¨åŸå§‹å¸§ä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœå åŠ å±‚
        ä½¿ç”¨æœ€æ–°çš„æ£€æµ‹ç»“æœï¼Œä½†ä¸é˜»å¡ç­‰å¾…æ–°æ£€æµ‹
        """
        h, w = frame.shape[:2]
        output = frame.copy()
        
        # è·å–æœ€æ–°æ£€æµ‹ç»“æœ
        with self._result_lock:
            detection_info = self._latest_result
            processed_frame = self._latest_processed_frame
        
        current_mode = self.get_mode()
        
        if current_mode == DetectionMode.ZONE:
            # ç»˜åˆ¶å±é™©åŒºåŸŸå’Œå®‰å…¨åŒºåŸŸ
            overlay = output.copy()
            for zone in self.zone_detector.danger_zones:
                cv2.fillPoly(overlay, [zone], (0, 0, 200))
                cv2.polylines(output, [zone], True, (0, 0, 255), 2)
            for zone in self.zone_detector.safe_zones:
                cv2.fillPoly(overlay, [zone], (0, 200, 0))
                cv2.polylines(output, [zone], True, (0, 255, 0), 2)
            cv2.addWeighted(overlay, 0.3, output, 0.7, 0, output)
            
            # ç»˜åˆ¶è­¦æˆ’çº¿
            mid_x = w // 2
            cv2.line(output, (mid_x, 0), (mid_x, h), (0, 255, 255), 2)
            cv2.putText(output, "WARNING LINE", (mid_x + 10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
            
            # ç»˜åˆ¶æ£€æµ‹æ¡†ï¼ˆä½¿ç”¨ç¼“å­˜çš„æ£€æµ‹ç»“æœï¼‰
            for detection in self.zone_detector.last_detections:
                x1, y1, x2, y2, conf = detection
                center = self.zone_detector._get_person_center((x1, y1, x2, y2))
                in_danger = any(self.zone_detector._point_in_zone(center, zone) 
                               for zone in self.zone_detector.danger_zones)
                
                if in_danger:
                    color = (0, 0, 255)
                    label = "DANGER!"
                else:
                    color = (0, 255, 0)
                    label = "Person"
                
                cv2.rectangle(output, (x1, y1), (x2, y2), color, 2)
                cv2.putText(output, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
                cv2.circle(output, center, 4, color, -1)
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            stats = self.zone_detector.statistics
            y_offset = 30
            
            if stats.current_in_danger > 0:
                cv2.putText(output, f"WARNING: {stats.current_in_danger} in DANGER ZONE!", (10, y_offset),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
                y_offset += 30
            
            cv2.putText(output, f"Persons: {len(self.zone_detector.last_detections)}", (10, y_offset),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            y_offset += 25
            
            cv2.putText(output, f"In Danger: {stats.current_in_danger}", (10, y_offset),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
            y_offset += 25
            
            cv2.putText(output, f"Entries: {stats.total_entries} | Exits: {stats.total_exits}", (10, y_offset),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 200, 100), 1)
            
            cv2.putText(output, "[ZONE MODE - ASYNC]", (w - 200, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        else:
            # äº§å“æ£€æµ‹æ¨¡å¼ - ä½¿ç”¨å¤„ç†åçš„å¸§ï¼ˆå¦‚æœæœ‰ï¼‰
            if processed_frame is not None and detection_info and detection_info.get("mode") == "product":
                return processed_frame
            
            # ç»˜åˆ¶æ£€æµ‹åŒºåŸŸ
            cv2.rectangle(output, (50, 50), (w-50, h-50), (100, 100, 100), 2)
            cv2.putText(output, "Detection Area", (55, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (100, 100, 100), 1)
            
            # ç»Ÿè®¡ä¿¡æ¯
            cv2.putText(output, f"Product A: {self.product_detector.detection_count['product_a']}", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, self.product_detector.COLOR_RANGES["product_a"]["display_color"], 2)
            cv2.putText(output, f"Product B: {self.product_detector.detection_count['product_b']}", (10, 55),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, self.product_detector.COLOR_RANGES["product_b"]["display_color"], 2)
            
            cv2.putText(output, "[PRODUCT MODE - ASYNC]", (w - 220, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 150, 50), 2)
        
        return output
    
    def run(self, headless: bool = False):
        """è¿è¡Œæ£€æµ‹ç³»ç»Ÿ"""
        # åˆå§‹åŒ–æ£€æµ‹å™¨
        self.init_detectors()
        
        # æ‰“å¼€æ‘„åƒå¤´ - æ”¯æŒæ ‘è“æ´¾CSIæ‘„åƒå¤´
        self.picam2 = None  # picamera2 å®ä¾‹
        self.use_picamera2 = False
        
        if IS_LINUX and PICAMERA2_AVAILABLE:
            # ä¼˜å…ˆä½¿ç”¨ picamera2ï¼ˆæ ‘è“æ´¾CSIæ‘„åƒå¤´æœ€ä½³æ–¹æ¡ˆï¼‰
            try:
                print("å°è¯•ä½¿ç”¨ picamera2 æ‰“å¼€æ‘„åƒå¤´...")
                self.picam2 = Picamera2()
                config = self.picam2.create_preview_configuration(
                    main={"size": (CAMERA_WIDTH, CAMERA_HEIGHT), "format": "RGB888"}
                )
                self.picam2.configure(config)
                self.picam2.start()
                self.use_picamera2 = True
                print("âœ“ ä½¿ç”¨ picamera2 æ‰“å¼€æ‘„åƒå¤´æˆåŠŸ")
            except Exception as e:
                print(f"picamera2 æ‰“å¼€å¤±è´¥: {e}")
                self.picam2 = None
        
        if not self.use_picamera2:
            if IS_LINUX:
                # æ ‘è“æ´¾CSIæ‘„åƒå¤´ - å°è¯•å…¶ä»–æ–¹å¼
                camera_opened = False
                
                # æ–¹æ³•1: ä½¿ç”¨ /dev/video0
                print("å°è¯•æ‰“å¼€æ‘„åƒå¤´...")
                self.cap = cv2.VideoCapture(0, cv2.CAP_V4L2)
                if self.cap.isOpened():
                    camera_opened = True
                    print("âœ“ ä½¿ç”¨ V4L2 æ‰“å¼€æ‘„åƒå¤´æˆåŠŸ")
                
                # æ–¹æ³•2: ç›´æ¥æ‰“å¼€
                if not camera_opened:
                    print("å°è¯•ç›´æ¥æ‰“å¼€æ‘„åƒå¤´...")
                    self.cap = cv2.VideoCapture(self.camera_id)
                    if self.cap.isOpened():
                        camera_opened = True
                        print("âœ“ ç›´æ¥æ‰“å¼€æ‘„åƒå¤´æˆåŠŸ")
                
                if camera_opened:
                    self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAMERA_WIDTH)
                    self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAMERA_HEIGHT)
                    self.cap.set(cv2.CAP_PROP_FPS, 30)
                    self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
            else:
                # Windows/å…¶ä»–ç³»ç»Ÿä½¿ç”¨é»˜è®¤æ–¹å¼
                self.cap = cv2.VideoCapture(self.camera_id)
                self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAMERA_WIDTH)
                self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAMERA_HEIGHT)
                self.cap.set(cv2.CAP_PROP_FPS, 30)
                self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        
        if not self.use_picamera2 and (self.cap is None or not self.cap.isOpened()):
            print("é”™è¯¯ï¼šæ— æ³•æ‰“å¼€æ‘„åƒå¤´")
            print("æç¤ºï¼šå¦‚æœä½¿ç”¨æ ‘è“æ´¾CSIæ‘„åƒå¤´ï¼Œè¯·å°è¯•ï¼š")
            print("  1. è¿è¡Œ 'rpicam-hello' ç¡®è®¤æ‘„åƒå¤´æ­£å¸¸")
            print("  2. ç¡®ä¿å·²å®‰è£… picamera2: sudo apt install python3-picamera2")
            return
        
        
        print("\n" + "="*60)
        print("ğŸ¬ ç»Ÿä¸€æ£€æµ‹ç³»ç»Ÿå·²å¯åŠ¨")
        print(f"ğŸ“¹ æ‘„åƒå¤´: {self.camera_id} | åˆ†è¾¨ç‡: {CAMERA_WIDTH}x{CAMERA_HEIGHT}")
        print("-"*60)
        print("æ“ä½œè¯´æ˜:")
        print("  '1' - åˆ‡æ¢åˆ°å±é™©åŒºåŸŸæ£€æµ‹æ¨¡å¼")
        print("  '2' - åˆ‡æ¢åˆ°äº§å“æ£€æµ‹æ¨¡å¼")
        print("  'c' - æ‰‹åŠ¨æ•è·äº§å“ï¼ˆäº§å“æ¨¡å¼ä¸‹ï¼‰")
        print("  'r' - é‡ç½®è®¡æ•°ï¼ˆäº§å“è®¡æ•°/å±é™©åŒºç»Ÿè®¡ï¼‰")
        print("  's' - æ˜¾ç¤ºå½“å‰ç»Ÿè®¡ä¿¡æ¯")
        print("  'q' - é€€å‡ºç¨‹åº")
        print("-"*60)
        print("ğŸ”” å±é™©åŒºåŸŸæ£€æµ‹è¯´æ˜:")
        print("  - äººå‘˜è¿›å…¥å±é™©åŒºï¼šæŠ¥è­¦ä¸€æ¬¡ + ç»Ÿè®¡è¿›å…¥æ¬¡æ•°")
        print("  - äººå‘˜ç¦»å¼€å±é™©åŒºï¼šé€šçŸ¥ä¸€æ¬¡ + ç»Ÿè®¡ç¦»å¼€æ¬¡æ•°")
        print("  - å®æ—¶æ˜¾ç¤ºå½“å‰åœç•™åœ¨å±é™©åŒºçš„äººæ•°")
        print("="*60 + "\n")
        
        self.running = True
        window_name = "Unified Detection System"
        
        if not headless:
            cv2.namedWindow(window_name)
        
        # ========== å¯åŠ¨å¼‚æ­¥æ£€æµ‹çº¿ç¨‹ ==========
        self._detection_running = True
        self._detection_thread = threading.Thread(target=self._detection_worker, daemon=True)
        self._detection_thread.start()
        print("âœ“ å¼‚æ­¥æ£€æµ‹æ¨¡å¼å·²å¯ç”¨ï¼ˆç”»é¢æµç•…ï¼Œæ£€æµ‹ç‹¬ç«‹è¿è¡Œï¼‰")
        
        fps_start_time = time.time()
        fps_frame_count = 0
        fps = 0
        
        try:
            while self.running:
                # è¯»å–å¸§ - æ”¯æŒ picamera2 å’Œ OpenCV
                if self.use_picamera2:
                    frame = self.picam2.capture_array()
                    # picamera2 è¿”å› RGBï¼Œéœ€è¦è½¬æ¢ä¸º BGRï¼ˆOpenCVæ ¼å¼ï¼‰
                    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                    ret = True
                else:
                    ret, frame = self.cap.read()
                
                if not ret or frame is None:
                    print("é”™è¯¯ï¼šæ— æ³•è¯»å–å¸§")
                    break
                
                # æ›´æ–°æœ€æ–°å¸§ä¾›æ£€æµ‹çº¿ç¨‹ä½¿ç”¨
                with self._frame_lock:
                    self._latest_frame = frame.copy()
                
                # æ£€æŸ¥æœåŠ¡å™¨æ¨¡å¼ï¼ˆä½é¢‘ç‡ï¼‰
                self._check_mode_from_server()
                
                # åœ¨åŸå§‹å¸§ä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœå åŠ å±‚ï¼ˆä¸é˜»å¡ï¼‰
                display_frame = self._draw_overlay_on_frame(frame)
                
                # æ¨é€è§†é¢‘æµ
                if ENABLE_VIDEO_STREAM:
                    with self._result_lock:
                        detection_info = self._latest_result
                    if detection_info:
                        self._stream_frame(display_frame, detection_info)
                
                # è®¡ç®—FPS
                fps_frame_count += 1
                if fps_frame_count >= 10:
                    fps = fps_frame_count / (time.time() - fps_start_time)
                    fps_start_time = time.time()
                    fps_frame_count = 0
                
                cv2.putText(display_frame, f"FPS: {fps:.1f}", (10, CAMERA_HEIGHT - 10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                # æ˜¾ç¤ºæ“ä½œæç¤º
                cv2.putText(display_frame, "1:Zone 2:Product c:Capture r:Reset q:Quit",
                           (10, CAMERA_HEIGHT - 35), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
                
                if not headless:
                    cv2.imshow(window_name, display_frame)
                    key = cv2.waitKey(1) & 0xFF
                    
                    if key == ord('q'):
                        print("\næ­£åœ¨é€€å‡º...")
                        break
                    elif key == ord('1'):
                        self.set_mode(DetectionMode.ZONE)
                    elif key == ord('2'):
                        self.set_mode(DetectionMode.PRODUCT)
                    elif key == ord('c') and self.get_mode() == DetectionMode.PRODUCT:
                        result = self.product_detector.capture(frame)
                        if result and self.server:
                            self.server.report_product(result)
                    elif key == ord('r'):
                        # é‡ç½®è®¡æ•°
                        if self.get_mode() == DetectionMode.PRODUCT:
                            self.product_detector.reset_count()
                        else:
                            self.zone_detector.reset_statistics()
                    elif key == ord('s'):
                        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                        self._print_statistics()
                else:
                    time.sleep(0.01)
                    
        except KeyboardInterrupt:
            print("\n\næ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...")
        finally:
            self.running = False
            
            # åœæ­¢æ£€æµ‹çº¿ç¨‹
            self._detection_running = False
            if self._detection_thread and self._detection_thread.is_alive():
                self._detection_thread.join(timeout=2.0)
                print("âœ“ æ£€æµ‹çº¿ç¨‹å·²åœæ­¢")
            
            # é‡Šæ”¾æ‘„åƒå¤´èµ„æº
            if self.use_picamera2 and self.picam2:
                self.picam2.stop()
                print("âœ“ picamera2 å·²åœæ­¢")
            elif self.cap:
                self.cap.release()
            if not headless:
                cv2.destroyAllWindows()
            self.gpio.cleanup()
            print("âœ“ ç¨‹åºå·²å®‰å…¨é€€å‡º")
            self._print_statistics()
    
    def _print_statistics(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "="*50)
        print("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯æ±‡æ€»")
        print("="*50)
        
        # å±é™©åŒºåŸŸç»Ÿè®¡
        zone_stats = self.zone_detector.get_statistics()
        print("\nğŸš¨ å±é™©åŒºåŸŸæ£€æµ‹ç»Ÿè®¡:")
        print(f"  æ€»è¿›å…¥æ¬¡æ•°: {zone_stats['total_entries']}")
        print(f"  æ€»ç¦»å¼€æ¬¡æ•°: {zone_stats['total_exits']}")
        print(f"  å½“å‰å±é™©åŒºäººæ•°: {zone_stats['current_in_danger']}")
        
        # äº§å“æ£€æµ‹ç»Ÿè®¡
        print(f"\nğŸ“¦ äº§å“æ£€æµ‹ç»Ÿè®¡:")
        print(f"  äº§å“A: {self.product_detector.detection_count['product_a']}")
        print(f"  äº§å“B: {self.product_detector.detection_count['product_b']}")
        print("="*50)


# ==================== ä¸»ç¨‹åºå…¥å£ ====================
if __name__ == "__main__":
    system = UnifiedDetectionSystem(camera_id=0)
    system.run(headless=False)
