"""
YOLOv8 åŒºåŸŸæ£€æµ‹ç³»ç»Ÿ - æ ‘è“æ´¾/Windows è·¨å¹³å°ç‰ˆ
åŠŸèƒ½ï¼š
1. æ£€æµ‹äººå‘˜æ˜¯å¦è¿›å…¥å±é™©åŒºåŸŸï¼ˆå±å¹•å³åŠéƒ¨åˆ†ï¼‰ï¼Œè¶Šçº¿å³æŠ¥è­¦
2. é€šè¿‡HTTP APIä¸ŠæŠ¥æ£€æµ‹ç»“æœåˆ°åç«¯
3. é€šè¿‡WebSocketæ¨é€è§†é¢‘æµåˆ°å‰ç«¯

ä¼˜åŒ–ï¼šé™ä½åˆ†è¾¨ç‡ã€è·³å¸§æ£€æµ‹ã€ä½¿ç”¨YOLOv8nã€å‡å°‘ç»˜åˆ¶å¼€é”€
ç‰¹æ€§ï¼šæ— éœ€äº¤äº’ï¼Œå¯åŠ¨åè‡ªåŠ¨è¿è¡Œï¼Œé¢„è®¾å±é™©åŒºåŸŸä¸ºå±å¹•å³åŠéƒ¨åˆ†
"""

import cv2
import numpy as np
from ultralytics import YOLO
from datetime import datetime
from dataclasses import dataclass
from typing import List, Tuple, Callable, Optional
import time
import threading
import platform
import subprocess
import base64
import json
import asyncio
import aiohttp

# æ£€æµ‹æ“ä½œç³»ç»Ÿ
IS_WINDOWS = platform.system() == "Windows"
IS_LINUX = platform.system() == "Linux"

if IS_WINDOWS:
    import winsound

# ==================== æœåŠ¡å™¨é…ç½® ====================
SERVER_URL = "http://localhost:8000"  # åç«¯æœåŠ¡å™¨åœ°å€
DEVICE_ID = "device_001"              # è®¾å¤‡ID
ENABLE_SERVER_REPORT = True           # æ˜¯å¦å¯ç”¨æ•°æ®ä¸ŠæŠ¥
ENABLE_VIDEO_STREAM = True            # æ˜¯å¦å¯ç”¨è§†é¢‘æµæ¨é€
VIDEO_STREAM_FPS = 10                 # è§†é¢‘æµå¸§ç‡ï¼ˆé™ä½ä»¥å‡å°‘å¸¦å®½ï¼‰
VIDEO_QUALITY = 50                    # JPEGå‹ç¼©è´¨é‡ï¼ˆ1-100ï¼‰


@dataclass
class AlertInfo:
    """è­¦æŠ¥ä¿¡æ¯"""
    timestamp: str
    zone_type: str
    person_count: int
    message: str
    bbox: Tuple[int, int, int, int]


class ServerClient:
    """æœåŠ¡å™¨é€šä¿¡å®¢æˆ·ç«¯"""
    
    def __init__(self, server_url: str, device_id: str):
        self.server_url = server_url.rstrip('/')
        self.device_id = device_id
        self._session = None
        self._ws = None
        self._ws_connected = False
        self._loop = None
    
    def _get_loop(self):
        """è·å–æˆ–åˆ›å»ºäº‹ä»¶å¾ªç¯"""
        try:
            return asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            return loop
    
    def report_detection_sync(self, person_count: int, in_danger_zone: bool, alert_triggered: bool):
        """åŒæ­¥æ–¹å¼ä¸ŠæŠ¥æ£€æµ‹ç»“æœï¼ˆåœ¨å•ç‹¬çº¿ç¨‹ä¸­è°ƒç”¨ï¼‰"""
        import requests
        try:
            data = {
                "device_id": self.device_id,
                "person_count": person_count,
                "in_danger_zone": in_danger_zone,
                "alert_triggered": alert_triggered
            }
            response = requests.post(
                f"{self.server_url}/api/detection",
                json=data,
                timeout=2
            )
            return response.status_code == 200
        except Exception as e:
            return False
    
    def send_video_frame_sync(self, frame: np.ndarray, detection_info: dict = None):
        """åŒæ­¥æ–¹å¼å‘é€è§†é¢‘å¸§ï¼ˆé€šè¿‡HTTPï¼‰"""
        import requests
        try:
            # å‹ç¼©å›¾åƒä¸ºJPEG
            encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), VIDEO_QUALITY]
            _, buffer = cv2.imencode('.jpg', frame, encode_param)
            frame_base64 = base64.b64encode(buffer).decode('utf-8')
            
            data = {
                "device_id": self.device_id,
                "frame": frame_base64,
                "timestamp": datetime.now().isoformat(),
                "detection": detection_info
            }
            
            response = requests.post(
                f"{self.server_url}/api/video/frame",
                json=data,
                timeout=1
            )
            return response.status_code == 200
        except Exception:
            return False


# å…¨å±€æœåŠ¡å™¨å®¢æˆ·ç«¯
server_client = None


class ZoneDetector:
    """åŒºåŸŸæ£€æµ‹å™¨ - æ ‘è“æ´¾ä¼˜åŒ–ç‰ˆ"""
    
    def __init__(self, 
                 model_path: str = "yolov8n.pt",
                 frame_skip: int = 2,
                 input_size: Tuple[int, int] = (416, 416),
                 alert_cooldown: float = 2.0):
        print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
        self.model = YOLO(model_path)
        self.model.fuse()

        self.danger_zones: List[np.ndarray] = []
        self.safe_zones: List[np.ndarray] = []
        self.alert_callback: Optional[Callable[[AlertInfo], None]] = None
        self.person_class_id = 0
        
        self.frame_skip = frame_skip
        self.frame_count = 0
        self.input_size = input_size
        self.alert_cooldown = alert_cooldown
        self.last_alert_time = {}
        
        self.last_detections = []
        self.scale_x = 1.0
        self.scale_y = 1.0
        
        # è§†é¢‘æµç›¸å…³
        self.last_stream_time = 0
        self.stream_interval = 1.0 / VIDEO_STREAM_FPS
        
        print(f"æ¨¡å‹åŠ è½½å®Œæˆ | è·³å¸§: {frame_skip} | è¾“å…¥å°ºå¯¸: {input_size}")
        
    def add_danger_zone(self, points: List[Tuple[int, int]]):
        self.danger_zones.append(np.array(points, dtype=np.int32))
        print(f"âœ“ å±é™©åŒºåŸŸå·²æ·»åŠ : {points}")
        
    def add_safe_zone(self, points: List[Tuple[int, int]]):
        self.safe_zones.append(np.array(points, dtype=np.int32))
        print(f"âœ“ å®‰å…¨åŒºåŸŸå·²æ·»åŠ : {points}")
        
    def clear_zones(self):
        self.danger_zones.clear()
        self.safe_zones.clear()
        
    def set_alert_callback(self, callback: Callable[[AlertInfo], None]):
        self.alert_callback = callback
        
    def _point_in_zone(self, point: Tuple[int, int], zone: np.ndarray) -> bool:
        return cv2.pointPolygonTest(zone, point, False) >= 0
    
    def _get_person_center(self, bbox: Tuple[int, int, int, int]) -> Tuple[int, int]:
        x1, y1, x2, y2 = bbox
        return (int((x1 + x2) / 2), int(y2))
    
    def _should_send_alert(self, zone_id: str) -> bool:
        current_time = time.time()
        if zone_id not in self.last_alert_time:
            self.last_alert_time[zone_id] = current_time
            return True
        
        if current_time - self.last_alert_time[zone_id] > self.alert_cooldown:
            self.last_alert_time[zone_id] = current_time
            return True
        return False
    
    def _check_zones(self, center: Tuple[int, int], bbox: Tuple[int, int, int, int]) -> List[AlertInfo]:
        alerts = []
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        for i, zone in enumerate(self.danger_zones):
            if self._point_in_zone(center, zone):
                zone_id = f"danger_{i}"
                if self._should_send_alert(zone_id):
                    alert = AlertInfo(
                        timestamp=timestamp,
                        zone_type="danger",
                        person_count=1,
                        message=f"âš ï¸ è­¦å‘Šï¼šæ£€æµ‹åˆ°äººå‘˜è¿›å…¥å±é™©åŒºåŸŸ {i+1}ï¼",
                        bbox=bbox
                    )
                    alerts.append(alert)
                
        for i, zone in enumerate(self.safe_zones):
            if self._point_in_zone(center, zone):
                alert = AlertInfo(
                    timestamp=timestamp,
                    zone_type="safe",
                    person_count=1,
                    message=f"âœ“ äººå‘˜åœ¨å®‰å…¨åŒºåŸŸ {i+1}",
                    bbox=bbox
                )
                alerts.append(alert)
                
        return alerts


    def detect_frame(self, frame: np.ndarray, conf_threshold: float = 0.5) -> Tuple[np.ndarray, List[AlertInfo], dict]:
        """
        æ£€æµ‹å•å¸§å›¾åƒ
        
        Returns:
            å¤„ç†åçš„å›¾åƒã€è­¦æŠ¥åˆ—è¡¨ã€æ£€æµ‹ä¿¡æ¯å­—å…¸
        """
        all_alerts = []
        h_orig, w_orig = frame.shape[:2]
        
        self.frame_count += 1
        should_detect = (self.frame_count % self.frame_skip == 0)
        
        if should_detect:
            if self.input_size:
                resized = cv2.resize(frame, self.input_size)
                self.scale_x = w_orig / self.input_size[0]
                self.scale_y = h_orig / self.input_size[1]
            else:
                resized = frame
                self.scale_x = 1.0
                self.scale_y = 1.0
            
            results = self.model(resized, conf=conf_threshold, classes=[self.person_class_id], 
                               verbose=False, device='cpu')
            
            self.last_detections = []
            for result in results:
                boxes = result.boxes
                for box in boxes:
                    x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
                    conf = float(box.conf[0])
                    
                    x1 = int(x1 * self.scale_x)
                    y1 = int(y1 * self.scale_y)
                    x2 = int(x2 * self.scale_x)
                    y2 = int(y2 * self.scale_y)
                    
                    self.last_detections.append((x1, y1, x2, y2, conf))
        
        danger_count = 0
        person_count = len(self.last_detections)
        in_danger_zone = False
        
        # ç»˜åˆ¶åŒºåŸŸ
        if len(self.danger_zones) > 0 or len(self.safe_zones) > 0:
            overlay = frame.copy()
            
            for zone in self.danger_zones:
                cv2.fillPoly(overlay, [zone], (0, 0, 200))
                cv2.polylines(frame, [zone], True, (0, 0, 255), 2)
                
            for zone in self.safe_zones:
                cv2.fillPoly(overlay, [zone], (0, 200, 0))
                cv2.polylines(frame, [zone], True, (0, 255, 0), 2)
                
            cv2.addWeighted(overlay, 0.3, frame, 0.7, 0, frame)
        
        # ç»˜åˆ¶ä¸­çº¿è­¦æˆ’çº¿
        mid_x = w_orig // 2
        cv2.line(frame, (mid_x, 0), (mid_x, h_orig), (0, 255, 255), 2)
        cv2.putText(frame, "WARNING LINE", (mid_x + 10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        # å¤„ç†æ£€æµ‹ç»“æœ
        for detection in self.last_detections:
            x1, y1, x2, y2, conf = detection
            bbox = (x1, y1, x2, y2)
            center = self._get_person_center(bbox)
            
            if should_detect:
                alerts = self._check_zones(center, bbox)
                all_alerts.extend(alerts)
            
            in_danger = any(self._point_in_zone(center, zone) for zone in self.danger_zones)
            
            if in_danger:
                danger_count += 1
                in_danger_zone = True
                color = (0, 0, 255)
                label = "DANGER!"
            else:
                color = (0, 255, 0)
                label = "Person"
            
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            cv2.putText(frame, label, (x1, y1 - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
            cv2.circle(frame, center, 4, color, -1)
        
        # æ˜¾ç¤ºè­¦å‘Šä¿¡æ¯
        if danger_count > 0:
            warning_text = f"WARNING: {danger_count} in DANGER ZONE!"
            cv2.putText(frame, warning_text, (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
        
        # æ˜¾ç¤ºäººæ•°ç»Ÿè®¡
        cv2.putText(frame, f"Persons: {person_count}", (10, 60),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
        # è§¦å‘å›è°ƒ
        if should_detect:
            for alert in all_alerts:
                if alert.zone_type == "danger" and self.alert_callback:
                    self.alert_callback(alert)
        
        # æ£€æµ‹ä¿¡æ¯
        detection_info = {
            "person_count": person_count,
            "in_danger_zone": in_danger_zone,
            "alert_triggered": danger_count > 0 and should_detect,
            "danger_count": danger_count
        }
                
        return frame, all_alerts, detection_info

    def run_camera(self, 
                   camera_id: int = 0, 
                   window_name: str = "Zone Detection",
                   display_fps: bool = True,
                   camera_width: int = 640,
                   camera_height: int = 480,
                   headless: bool = False):
        """è¿è¡Œæ‘„åƒå¤´æ£€æµ‹"""
        global server_client
        
        cap = cv2.VideoCapture(camera_id)
        
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, camera_width)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, camera_height)
        cap.set(cv2.CAP_PROP_FPS, 30)
        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        
        if not cap.isOpened():
            print("é”™è¯¯ï¼šæ— æ³•æ‰“å¼€æ‘„åƒå¤´")
            return
            
        print("="*60)
        print("ğŸš€ åŒºåŸŸæ£€æµ‹ç³»ç»Ÿå·²å¯åŠ¨")
        print(f"ğŸ“¹ æ‘„åƒå¤´: {camera_id} | åˆ†è¾¨ç‡: {camera_width}x{camera_height}")
        print(f"âš ï¸  å±é™©åŒºåŸŸæ•°é‡: {len(self.danger_zones)}")
        print(f"âœ… å®‰å…¨åŒºåŸŸæ•°é‡: {len(self.safe_zones)}")
        if ENABLE_SERVER_REPORT:
            print(f"ğŸ“¡ æ•°æ®ä¸ŠæŠ¥: {SERVER_URL}")
        if ENABLE_VIDEO_STREAM:
            print(f"ğŸ“º è§†é¢‘æµ: å·²å¯ç”¨ ({VIDEO_STREAM_FPS} FPS)")
        print("æŒ‰ 'q' é”®é€€å‡ºç¨‹åº")
        print("="*60)
        
        fps_start_time = time.time()
        fps_frame_count = 0
        fps = 0
        
        if not headless:
            cv2.namedWindow(window_name)
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    print("é”™è¯¯ï¼šæ— æ³•è¯»å–å¸§")
                    break
                
                # æ£€æµ‹
                processed_frame, alerts, detection_info = self.detect_frame(frame)
                
                # ä¸ŠæŠ¥æ£€æµ‹ç»“æœåˆ°æœåŠ¡å™¨
                if ENABLE_SERVER_REPORT and detection_info["alert_triggered"]:
                    self._report_to_server(detection_info)
                
                # æ¨é€è§†é¢‘æµ
                if ENABLE_VIDEO_STREAM:
                    self._stream_video_frame(processed_frame, detection_info)
                
                # è®¡ç®—FPS
                if display_fps:
                    fps_frame_count += 1
                    if fps_frame_count >= 10:
                        fps = fps_frame_count / (time.time() - fps_start_time)
                        fps_start_time = time.time()
                        fps_frame_count = 0
                    
                    cv2.putText(processed_frame, f"FPS: {fps:.1f}", (10, frame.shape[0] - 10),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                if not headless:
                    cv2.imshow(window_name, processed_frame)
                    key = cv2.waitKey(1) & 0xFF
                    if key == ord('q'):
                        print("\næ­£åœ¨é€€å‡º...")
                        break
                else:
                    time.sleep(0.01)
                    
        except KeyboardInterrupt:
            print("\n\næ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...")
        finally:
            cap.release()
            if not headless:
                cv2.destroyAllWindows()
            print("âœ“ ç¨‹åºå·²å®‰å…¨é€€å‡º")
    
    def _report_to_server(self, detection_info: dict):
        """ä¸ŠæŠ¥æ£€æµ‹ç»“æœåˆ°æœåŠ¡å™¨ï¼ˆå¼‚æ­¥ï¼‰"""
        global server_client
        if server_client:
            def _report():
                server_client.report_detection_sync(
                    person_count=detection_info["person_count"],
                    in_danger_zone=detection_info["in_danger_zone"],
                    alert_triggered=detection_info["alert_triggered"]
                )
            thread = threading.Thread(target=_report)
            thread.daemon = True
            thread.start()
    
    def _stream_video_frame(self, frame: np.ndarray, detection_info: dict):
        """æ¨é€è§†é¢‘å¸§ï¼ˆé™åˆ¶å¸§ç‡ï¼‰"""
        global server_client
        current_time = time.time()
        
        if current_time - self.last_stream_time >= self.stream_interval:
            self.last_stream_time = current_time
            
            if server_client:
                def _stream():
                    server_client.send_video_frame_sync(frame, detection_info)
                thread = threading.Thread(target=_stream)
                thread.daemon = True
                thread.start()



# GPIOæ§åˆ¶ç±»ï¼ˆæ ‘è“æ´¾LEDå’Œèœ‚é¸£å™¨æ§åˆ¶ï¼‰
class GPIOController:
    """GPIOæ§åˆ¶å™¨ - ç®¡ç†LEDå’Œèœ‚é¸£å™¨"""
    
    def __init__(self, led_pin: int = 16, buzzer_pin: int = 18):
        self.led_pin = led_pin
        self.buzzer_pin = buzzer_pin
        self.gpio_initialized = False
        self.led_state = False
        
        if IS_LINUX:
            try:
                import RPi.GPIO as GPIO
                self.GPIO = GPIO
                GPIO.setmode(GPIO.BCM)
                GPIO.setwarnings(False)
                
                GPIO.setup(self.led_pin, GPIO.OUT)
                GPIO.output(self.led_pin, GPIO.LOW)
                
                GPIO.setup(self.buzzer_pin, GPIO.OUT)
                GPIO.output(self.buzzer_pin, GPIO.LOW)
                
                self.gpio_initialized = True
                print(f"âœ“ GPIOåˆå§‹åŒ–æˆåŠŸ | LEDå¼•è„š: {led_pin} | èœ‚é¸£å™¨å¼•è„š: {buzzer_pin}")
                
            except ImportError:
                print("âš ï¸ RPi.GPIOæœªå®‰è£…ï¼ŒLEDå’Œèœ‚é¸£å™¨åŠŸèƒ½å°†è¢«ç¦ç”¨")
            except Exception as e:
                print(f"âš ï¸ GPIOåˆå§‹åŒ–å¤±è´¥: {e}")
    
    def turn_on_led(self):
        if self.gpio_initialized and not self.led_state:
            try:
                self.GPIO.output(self.led_pin, self.GPIO.HIGH)
                self.led_state = True
                print("ğŸ”´ LEDå·²ç‚¹äº®")
            except Exception as e:
                print(f"LEDç‚¹äº®å¤±è´¥: {e}")
    
    def turn_off_led(self):
        if self.gpio_initialized and self.led_state:
            try:
                self.GPIO.output(self.led_pin, self.GPIO.LOW)
                self.led_state = False
                print("âš« LEDå·²ç†„ç­")
            except Exception as e:
                print(f"LEDç†„ç­å¤±è´¥: {e}")
    
    def buzzer_beep(self, duration: float = 0.5):
        if self.gpio_initialized:
            try:
                self.GPIO.output(self.buzzer_pin, self.GPIO.HIGH)
                time.sleep(duration)
                self.GPIO.output(self.buzzer_pin, self.GPIO.LOW)
            except Exception as e:
                print(f"èœ‚é¸£å™¨å“å£°å¤±è´¥: {e}")
    
    def cleanup(self):
        if self.gpio_initialized:
            try:
                self.GPIO.cleanup()
                print("âœ“ GPIOèµ„æºå·²æ¸…ç†")
            except Exception as e:
                print(f"GPIOæ¸…ç†å¤±è´¥: {e}")


# å…¨å±€GPIOæ§åˆ¶å™¨å®ä¾‹
gpio_controller = None


def play_alarm_sound():
    """æ’­æ”¾æŠ¥è­¦å£°éŸ³ï¼ˆè·¨å¹³å°æ”¯æŒï¼‰"""
    global gpio_controller
    
    try:
        if IS_WINDOWS:
            winsound.Beep(1000, 500)
        elif IS_LINUX:
            try:
                subprocess.run(['aplay', '-q', '/usr/share/sounds/alsa/Front_Center.wav'], 
                             timeout=2, check=False)
            except FileNotFoundError:
                pass
            
            if gpio_controller:
                gpio_controller.buzzer_beep(0.5)
            
            print('\a')
    except Exception as e:
        print(f"æŠ¥è­¦å£°éŸ³æ’­æ”¾å¤±è´¥: {e}")


def control_led_alarm():
    """æ§åˆ¶LEDæŠ¥è­¦ç¯"""
    global gpio_controller
    
    if gpio_controller:
        gpio_controller.turn_on_led()
        
        def auto_turn_off():
            time.sleep(3.0)
            gpio_controller.turn_off_led()
        
        led_thread = threading.Thread(target=auto_turn_off)
        led_thread.start()


def alert_handler(alert: AlertInfo):
    """é»˜è®¤è­¦æŠ¥å¤„ç†å‡½æ•° - è¶Šçº¿æŠ¥è­¦"""
    if alert.zone_type == "danger":
        print(f"\n{'='*50}")
        print(f"ğŸš¨ {alert.timestamp} - {alert.message}")
        print(f"âš ï¸  è­¦å‘Šï¼šæœ‰äººè¶Šè¿‡è­¦æˆ’çº¿ï¼")
        print(f"ğŸ“ ä½ç½®: {alert.bbox}")
        print(f"{'='*50}\n")
        
        # æ’­æ”¾æŠ¥è­¦å£°
        alarm_thread = threading.Thread(target=play_alarm_sound)
        alarm_thread.start()
        
        # æ§åˆ¶LED
        led_thread = threading.Thread(target=control_led_alarm)
        led_thread.start()


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    CAMERA_WIDTH = 640
    CAMERA_HEIGHT = 480
    
    # åˆå§‹åŒ–æœåŠ¡å™¨å®¢æˆ·ç«¯
    if ENABLE_SERVER_REPORT or ENABLE_VIDEO_STREAM:
        server_client = ServerClient(SERVER_URL, DEVICE_ID)
        print(f"âœ“ æœåŠ¡å™¨å®¢æˆ·ç«¯å·²åˆå§‹åŒ–: {SERVER_URL}")
    
    # åˆå§‹åŒ–GPIOæ§åˆ¶å™¨
    gpio_controller = GPIOController(led_pin=16, buzzer_pin=18)
    
    # åˆ›å»ºæ£€æµ‹å™¨
    detector = ZoneDetector(
        model_path="yolov8n.pt",
        frame_skip=3,
        input_size=(320, 320),
        alert_cooldown=3.0
    )
    
    # è®¾ç½®è­¦æŠ¥å›è°ƒ
    detector.set_alert_callback(alert_handler)
    
    # é…ç½®å±é™©åŒºåŸŸï¼ˆå±å¹•å³åŠéƒ¨åˆ†ï¼‰
    detector.add_danger_zone([
        (CAMERA_WIDTH // 2, 0),
        (CAMERA_WIDTH, 0),
        (CAMERA_WIDTH, CAMERA_HEIGHT),
        (CAMERA_WIDTH // 2, CAMERA_HEIGHT)
    ])
    
    # é…ç½®å®‰å…¨åŒºåŸŸï¼ˆå±å¹•å·¦åŠéƒ¨åˆ†ï¼‰
    detector.add_safe_zone([
        (0, 0),
        (CAMERA_WIDTH // 2, 0),
        (CAMERA_WIDTH // 2, CAMERA_HEIGHT),
        (0, CAMERA_HEIGHT)
    ])
    
    print("\n" + "="*60)
    print("âš ï¸  å±é™©åŒºåŸŸï¼šå±å¹•å³åŠéƒ¨åˆ†")
    print("âœ… å®‰å…¨åŒºåŸŸï¼šå±å¹•å·¦åŠéƒ¨åˆ†")
    print("ğŸ“ è­¦æˆ’çº¿ï¼šå±å¹•ä¸­å¤®å‚ç›´çº¿")
    print("ğŸš¨ è¶Šè¿‡è­¦æˆ’çº¿è¿›å…¥å³ä¾§åŒºåŸŸå°†è§¦å‘æŠ¥è­¦ï¼")
    print("="*60 + "\n")
    
    try:
        detector.run_camera(
            camera_id=0,
            camera_width=CAMERA_WIDTH,
            camera_height=CAMERA_HEIGHT,
            display_fps=True,
            headless=False
        )
    finally:
        if gpio_controller:
            gpio_controller.cleanup()
